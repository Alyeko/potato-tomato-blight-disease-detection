{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Contents\n1. [Introduction](#section-one)\n2. [Importing packages used](#section-two)\n3. [Data exploration](#section-three)\n4. [Data augmentation](#section-four)\n5. [Training](#section-five)\n    - 5a. [Images available for training](#subsection-five-a)\n    - 5b. [Data preparation for training](#subsection-five-b)\n6. [ResNet-9 model](#section-six)\n    - 6a. [Functions used to build the ResNet-9 model](#subsection-six-a)\n    - 6b. [ResNet-9 model implementation](#subsection-six-b)\n7. [Hyperparamter tuning with Optuna](#section-seven)\n    - 7a. [Visualizing the hyperparameter tuning process](#subsection-seven-a)\n8. [ResNet-9 model training with optimized hyperparameters](#section-eight)\n9. [Plotting training accuracies and losses](#section-nine)\n    - 9a. [Training Accuracies](#subsection-nine-a)\n    - 9a. [Losses](#subsection-nine-b)\n10. [Test data](#section-ten)\n     - 10a. [Test data preparation](#subsection-ten-a)\n     - 10b. [ResNet-9 model evaluation on test data](#subsection-ten-b)\n         - 10bi. [Confusion Matrix](#subsection-ten-bi)\n         - 10bi. [Test accuracy and classification report](#subsection-ten-bii)\n11. [Saving the model](#section-eleven)  \n12. [Model Explanations (DeepShap and Saliency Maps)](#section-twelve)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-one\"></a>\n## Introduction","metadata":{}},{"cell_type":"markdown","source":"The notebook contains the implementation, training and evaluation code for the ResNet-9 model in my thesis: Automatic Blight Disease Detection in Potato and Tomato Plants using Deep Learning'. This notebook also contains the code used to create saliency maps presented in the thesis. \n\nResNet-9 model training code in this notebook was adapted from https://www.kaggle.com/code/atharvaingle/plant-disease-classification-resnet-99-2/notebook","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>\n## Importing packages used","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:33:33.960636Z","iopub.execute_input":"2022-09-26T21:33:33.961598Z","iopub.status.idle":"2022-09-26T21:33:43.003898Z","shell.execute_reply.started":"2022-09-26T21:33:33.961557Z","shell.execute_reply":"2022-09-26T21:33:43.002605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os                                      \nimport sys\nimport shap                                    \nimport torch                                   \nimport shutil\nimport optuna\nimport warnings\nimport numpy as np                             \nimport pandas as pd                            \nimport torch.nn as nn                          \nfrom PIL import Image                          \nimport seaborn as sns\nimport matplotlib.pyplot as plt                \nimport torch.nn.functional as F                \nfrom torchsummary import summary               \nfrom torchvision.utils import make_grid        \nfrom torch.utils.data import DataLoader        \nimport torchvision.transforms as transforms   \nfrom torchvision.datasets import ImageFolder  \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:33:43.006950Z","iopub.execute_input":"2022-09-26T21:33:43.007355Z","iopub.status.idle":"2022-09-26T21:33:43.019402Z","shell.execute_reply.started":"2022-09-26T21:33:43.007315Z","shell.execute_reply":"2022-09-26T21:33:43.018458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>\n## Data exploration","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/pt-leaf-data/idata/Image Dataset/ImageDataset/')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:33:49.755473Z","iopub.execute_input":"2022-09-26T21:33:49.755830Z","iopub.status.idle":"2022-09-26T21:33:49.770354Z","shell.execute_reply.started":"2022-09-26T21:33:49.755800Z","shell.execute_reply":"2022-09-26T21:33:49.769346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_dir = '/kaggle/input/dataset/idata/Image Dataset/ImageDataset/'\n\ndata_dir = '/kaggle/input/pt-leaf-data/idata/Image Dataset/ImageDataset/'\ndata_dir","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:33:50.735551Z","iopub.execute_input":"2022-09-26T21:33:50.735911Z","iopub.status.idle":"2022-09-26T21:33:50.742599Z","shell.execute_reply.started":"2022-09-26T21:33:50.735880Z","shell.execute_reply":"2022-09-26T21:33:50.741375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f\"Number of image directories are {len(os.listdir(data_fpath))+len(os.listdir('/kaggle/input/newds/ImageDataset_new/ImageDataset_new/'))}\\n\")\nprint('Number of unique plants are 2, potato and tomato\\n')\nprint('Number of diseases are 4, early and late blight disease for tomato, early and late blight for potato\\n')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:34:06.875636Z","iopub.execute_input":"2022-09-26T21:34:06.876658Z","iopub.status.idle":"2022-09-26T21:34:06.882202Z","shell.execute_reply.started":"2022-09-26T21:34:06.876608Z","shell.execute_reply":"2022-09-26T21:34:06.881112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:34:09.390576Z","iopub.execute_input":"2022-09-26T21:34:09.390929Z","iopub.status.idle":"2022-09-26T21:34:09.397580Z","shell.execute_reply.started":"2022-09-26T21:34:09.390899Z","shell.execute_reply":"2022-09-26T21:34:09.396528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train and validation directories\ntrain_dir = data_dir + \"train/\"\nvalid_dir = data_dir + \"valid/\"\ndiseases_tr = os.listdir(train_dir)\ndiseases_va = os.listdir(valid_dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:34:09.806612Z","iopub.execute_input":"2022-09-26T21:34:09.806967Z","iopub.status.idle":"2022-09-26T21:34:09.826234Z","shell.execute_reply.started":"2022-09-26T21:34:09.806936Z","shell.execute_reply":"2022-09-26T21:34:09.825354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dir","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:34:11.569174Z","iopub.execute_input":"2022-09-26T21:34:11.569854Z","iopub.status.idle":"2022-09-26T21:34:11.576507Z","shell.execute_reply.started":"2022-09-26T21:34:11.569808Z","shell.execute_reply":"2022-09-26T21:34:11.575470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diseases_tr","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:41:20.745562Z","iopub.execute_input":"2022-09-26T21:41:20.745918Z","iopub.status.idle":"2022-09-26T21:41:20.752381Z","shell.execute_reply.started":"2022-09-26T21:41:20.745886Z","shell.execute_reply":"2022-09-26T21:41:20.751369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diseases = []\nNumberOfDiseases = 0\n\nfor disease in diseases_tr:\n    if disease != 'healthy':\n        diseases.append(disease)\n        NumberOfDiseases += 1\n        \ndiseases","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:42:14.677140Z","iopub.execute_input":"2022-09-26T21:42:14.677502Z","iopub.status.idle":"2022-09-26T21:42:14.685685Z","shell.execute_reply.started":"2022-09-26T21:42:14.677471Z","shell.execute_reply":"2022-09-26T21:42:14.684428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images for each clas in the training data\nnums_train = {}\nfor folder in sorted(os.listdir(f\"{data_dir}/train\")):\n    nums_train[folder] = len(os.listdir(f\"/{data_dir}/train/{folder}\"))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_training_class = pd.DataFrame(nums_train.values(), index=nums_train.keys(), columns=[\"no. of images\"])\nimg_per_training_class","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:43:12.623513Z","iopub.execute_input":"2022-09-26T21:43:12.623939Z","iopub.status.idle":"2022-09-26T21:43:13.213576Z","shell.execute_reply.started":"2022-09-26T21:43:12.623904Z","shell.execute_reply":"2022-09-26T21:43:13.212694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of images for each clas in the validation data\nnums_valid = {}\nfor folder in sorted(os.listdir(f\"{data_dir}/valid\")):\n    nums_valid[folder] = len(os.listdir(f\"{data_dir}/valid/{folder}\"))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_valid_class = pd.DataFrame(nums_valid.values(), index=nums_valid.keys(), columns=[\"no. of images\"])\nimg_per_valid_class","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:44:29.858642Z","iopub.execute_input":"2022-09-26T21:44:29.858993Z","iopub.status.idle":"2022-09-26T21:44:30.041229Z","shell.execute_reply.started":"2022-09-26T21:44:29.858961Z","shell.execute_reply":"2022-09-26T21:44:30.040313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting number of images available for each class\nindex = [n for n in range(3)]\nplt.figure(figsize=(8, 3))\nplt.bar(index, [n for n in nums_train.values()], color='#8528B0', width=0.7, align='center')\nplt.xlabel('Classes', fontsize=15)\nplt.ylabel('No of images', fontsize=15)\nplt.xticks(index, [key for key in nums_train.keys()], fontsize=15, rotation=90)\nplt.title('Images per class for training dataset', fontsize=15)\n\nplt.savefig('/kaggle/working/number_imgs_training.png', dpi=600, bbox_inches=\"tight\")  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:48:43.156591Z","iopub.execute_input":"2022-09-26T21:48:43.156953Z","iopub.status.idle":"2022-09-26T21:48:44.475777Z","shell.execute_reply.started":"2022-09-26T21:48:43.156921Z","shell.execute_reply":"2022-09-26T21:48:44.474869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting number of images available for each class\nindex = [n for n in range(3)]\nplt.figure(figsize=(8, 3))\nplt.bar(index, [n for n in nums_valid.values()], color='#8528B0', width=0.7) \nplt.xlabel('Classes', fontsize=15)\nplt.ylabel('No of images', fontsize=15)\nplt.xticks(index, [key for key in nums_valid.keys()], fontsize=15, rotation=90)\nplt.title('Images per class for validation dataset', fontsize=15)\n# plt.tight_layout()\nplt.savefig('/kaggle/working/number_imgs_validation.png', dpi=600, bbox_inches=\"tight\")  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:48:57.334029Z","iopub.execute_input":"2022-09-26T21:48:57.334435Z","iopub.status.idle":"2022-09-26T21:48:58.463973Z","shell.execute_reply.started":"2022-09-26T21:48:57.334404Z","shell.execute_reply":"2022-09-26T21:48:58.462999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>\n## Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"The data has already been augmented. See https://github.com/Alyeko/potato-tomato-blight-disease-detection for the code used to augment the data\n\nAlso see description of the dataset used in this notebook -> https://www.kaggle.com/datasets/alyeko/potato-tomato-dataset","metadata":{"execution":{"iopub.status.busy":"2022-07-08T19:53:01.18532Z","iopub.execute_input":"2022-07-08T19:53:01.185753Z","iopub.status.idle":"2022-07-08T19:53:01.192473Z","shell.execute_reply.started":"2022-07-08T19:53:01.185709Z","shell.execute_reply":"2022-07-08T19:53:01.191217Z"}}},{"cell_type":"markdown","source":"------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>\n## Training","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-five-a\"></a>\n### Images available for training","metadata":{}},{"cell_type":"code","source":"n_train = 0\nfor value in nums_train.values():\n    n_train += value\nprint(f\"There are {n_train} images for training\")","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:49:17.274972Z","iopub.execute_input":"2022-09-26T21:49:17.275656Z","iopub.status.idle":"2022-09-26T21:49:17.284826Z","shell.execute_reply.started":"2022-09-26T21:49:17.275616Z","shell.execute_reply":"2022-09-26T21:49:17.283146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_valid = 0\nfor value in nums_valid.values():\n    n_valid += value\nprint(f\"There are {n_valid} images for validation\")","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:49:25.147103Z","iopub.execute_input":"2022-09-26T21:49:25.147558Z","iopub.status.idle":"2022-09-26T21:49:25.153899Z","shell.execute_reply.started":"2022-09-26T21:49:25.147516Z","shell.execute_reply":"2022-09-26T21:49:25.152563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if here are non img files in the training data folder","metadata":{"execution":{"iopub.status.busy":"2022-09-08T16:03:57.091759Z","iopub.execute_input":"2022-09-08T16:03:57.092403Z","iopub.status.idle":"2022-09-08T16:03:57.118415Z","shell.execute_reply.started":"2022-09-08T16:03:57.092277Z","shell.execute_reply":"2022-09-08T16:03:57.11741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folds = [folder for folder in os.listdir(train_dir)]\nfolds","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:49:51.171576Z","iopub.execute_input":"2022-09-26T21:49:51.171935Z","iopub.status.idle":"2022-09-26T21:49:51.186331Z","shell.execute_reply.started":"2022-09-26T21:49:51.171902Z","shell.execute_reply":"2022-09-26T21:49:51.185347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in folds:\n    for img in os.listdir(train_dir+i):\n        if not img.endswith('.JPG'):\n            print('yes!')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:49:54.540481Z","iopub.execute_input":"2022-09-26T21:49:54.540847Z","iopub.status.idle":"2022-09-26T21:49:54.554633Z","shell.execute_reply.started":"2022-09-26T21:49:54.540816Z","shell.execute_reply":"2022-09-26T21:49:54.553647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in folds:\n    for img in os.listdir(valid_dir+i):\n        if not img.endswith('.JPG'):\n            print('yes!')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:49:59.590483Z","iopub.execute_input":"2022-09-26T21:49:59.591193Z","iopub.status.idle":"2022-09-26T21:49:59.599861Z","shell.execute_reply.started":"2022-09-26T21:49:59.591154Z","shell.execute_reply":"2022-09-26T21:49:59.598843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:50:16.667058Z","iopub.execute_input":"2022-09-26T21:50:16.667430Z","iopub.status.idle":"2022-09-26T21:50:16.674311Z","shell.execute_reply.started":"2022-09-26T21:50:16.667400Z","shell.execute_reply":"2022-09-26T21:50:16.673039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(os.listdir('/kaggle/input/pt-leaf-data/idata/Image Dataset/test_data/test'))} images for test\")","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:53:53.190791Z","iopub.execute_input":"2022-09-26T21:53:53.191924Z","iopub.status.idle":"2022-09-26T21:53:53.326689Z","shell.execute_reply.started":"2022-09-26T21:53:53.191878Z","shell.execute_reply":"2022-09-26T21:53:53.325629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training dir: {os.listdir('/kaggle/input/pt-leaf-data/idata/Image Dataset/ImageDataset/')}\")\nprint(f\"All: {os.listdir('/kaggle/input/pt-leaf-data/idata/Image Dataset')}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:54:25.344773Z","iopub.execute_input":"2022-09-26T21:54:25.345158Z","iopub.status.idle":"2022-09-26T21:54:25.352686Z","shell.execute_reply.started":"2022-09-26T21:54:25.345126Z","shell.execute_reply":"2022-09-26T21:54:25.351284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = '/kaggle/input/pt-leaf-data/idata/Image Dataset/test_data/'\n# print(f\"There are {len(os.listdir('/kaggle/input/newds/ImageDataset_new/ImageDataset_new/test_data'))} images for training\")\nos.listdir(test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:54:30.745421Z","iopub.execute_input":"2022-09-26T21:54:30.745777Z","iopub.status.idle":"2022-09-26T21:54:30.754918Z","shell.execute_reply.started":"2022-09-26T21:54:30.745746Z","shell.execute_reply":"2022-09-26T21:54:30.753799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img in os.listdir(test_dir+'test'):\n        if not img.endswith('.JPG'):\n            print('Yes! I knew it!')","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:54:35.646307Z","iopub.execute_input":"2022-09-26T21:54:35.646958Z","iopub.status.idle":"2022-09-26T21:54:35.656833Z","shell.execute_reply.started":"2022-09-26T21:54:35.646920Z","shell.execute_reply":"2022-09-26T21:54:35.655727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-five-b\"></a>\n### Data preparation for training ","metadata":{}},{"cell_type":"code","source":"print(train_dir)\nprint(valid_dir)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:54:46.305376Z","iopub.execute_input":"2022-09-26T21:54:46.305743Z","iopub.status.idle":"2022-09-26T21:54:46.311292Z","shell.execute_reply.started":"2022-09-26T21:54:46.305712Z","shell.execute_reply":"2022-09-26T21:54:46.310293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# datasets for validation and training\ntrain = ImageFolder(train_dir, transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))\n\nvalid = ImageFolder(valid_dir, transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:54:50.264759Z","iopub.execute_input":"2022-09-26T21:54:50.265141Z","iopub.status.idle":"2022-09-26T21:54:57.024758Z","shell.execute_reply.started":"2022-09-26T21:54:50.265106Z","shell.execute_reply":"2022-09-26T21:54:57.023746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Image shape\nimg, label = train[4590]\nprint(img.shape, label)\n\nimg, label = train[0]\nprint(img.shape, label)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:04.481256Z","iopub.execute_input":"2022-09-26T21:55:04.481624Z","iopub.status.idle":"2022-09-26T21:55:04.501949Z","shell.execute_reply.started":"2022-09-26T21:55:04.481595Z","shell.execute_reply":"2022-09-26T21:55:04.500626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the shape (3, 256 256) of the image. 3 is the number of channels (RGB) and 256 x 256 is the width and height of the image","metadata":{}},{"cell_type":"code","source":"len(train.classes) #multiclass classification with 3 classes","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:11.202466Z","iopub.execute_input":"2022-09-26T21:55:11.203444Z","iopub.status.idle":"2022-09-26T21:55:11.210446Z","shell.execute_reply.started":"2022-09-26T21:55:11.203408Z","shell.execute_reply":"2022-09-26T21:55:11.209307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for checking some images from training dataset\ndef show_image(image, label):\n    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n    plt.imshow(image.permute(1, 2, 0))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:20.543478Z","iopub.execute_input":"2022-09-26T21:55:20.543836Z","iopub.status.idle":"2022-09-26T21:55:20.549394Z","shell.execute_reply.started":"2022-09-26T21:55:20.543806Z","shell.execute_reply":"2022-09-26T21:55:20.548322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setting the seed value\nrandom_seed = 7\ntorch.manual_seed(random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:37.020567Z","iopub.execute_input":"2022-09-26T21:55:37.020931Z","iopub.status.idle":"2022-09-26T21:55:37.030322Z","shell.execute_reply.started":"2022-09-26T21:55:37.020899Z","shell.execute_reply":"2022-09-26T21:55:37.029108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[10000])","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:37.392358Z","iopub.execute_input":"2022-09-26T21:55:37.392735Z","iopub.status.idle":"2022-09-26T21:55:37.605551Z","shell.execute_reply.started":"2022-09-26T21:55:37.392704Z","shell.execute_reply":"2022-09-26T21:55:37.604562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[6580])","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:47.244002Z","iopub.execute_input":"2022-09-26T21:55:47.244721Z","iopub.status.idle":"2022-09-26T21:55:47.454471Z","shell.execute_reply.started":"2022-09-26T21:55:47.244683Z","shell.execute_reply":"2022-09-26T21:55:47.453583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[1000])","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:55.664328Z","iopub.execute_input":"2022-09-26T21:55:55.664687Z","iopub.status.idle":"2022-09-26T21:55:55.892791Z","shell.execute_reply.started":"2022-09-26T21:55:55.664657Z","shell.execute_reply":"2022-09-26T21:55:55.891928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_image(*train[5000])","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:55:56.639716Z","iopub.execute_input":"2022-09-26T21:55:56.640114Z","iopub.status.idle":"2022-09-26T21:55:56.852879Z","shell.execute_reply.started":"2022-09-26T21:55:56.640045Z","shell.execute_reply":"2022-09-26T21:55:56.852005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train, '\\n')\nprint(valid)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:03.954567Z","iopub.execute_input":"2022-09-26T21:56:03.955140Z","iopub.status.idle":"2022-09-26T21:56:03.962808Z","shell.execute_reply.started":"2022-09-26T21:56:03.955097Z","shell.execute_reply":"2022-09-26T21:56:03.961528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoaders for training and validation\n# setting the batch size\nbatch_size = 32\ntrain_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:09.668394Z","iopub.execute_input":"2022-09-26T21:56:09.668976Z","iopub.status.idle":"2022-09-26T21:56:09.674464Z","shell.execute_reply.started":"2022-09-26T21:56:09.668939Z","shell.execute_reply":"2022-09-26T21:56:09.673414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper function to show a batch of training instances\ndef show_batch(data):\n    for images, labels in data:\n        fig, ax = plt.subplots(figsize=(30, 30))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n        break\n        \n# Images for first batch of training\nshow_batch(train_dl) ","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:15.015261Z","iopub.execute_input":"2022-09-26T21:56:15.015676Z","iopub.status.idle":"2022-09-26T21:56:20.301734Z","shell.execute_reply.started":"2022-09-26T21:56:15.015637Z","shell.execute_reply":"2022-09-26T21:56:20.300159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>\n## ResNet-9 model","metadata":{"execution":{"iopub.status.busy":"2022-09-11T18:15:27.477792Z","iopub.execute_input":"2022-09-11T18:15:27.478468Z","iopub.status.idle":"2022-09-11T18:15:27.506067Z","shell.execute_reply.started":"2022-09-11T18:15:27.478343Z","shell.execute_reply":"2022-09-11T18:15:27.504992Z"}}},{"cell_type":"markdown","source":"<a id=\"subsection-six-a\"></a>\n### Functions used to build the ResNet-9 model ","metadata":{}},{"cell_type":"code","source":"# for moving data into GPU (if available)\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available:\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n\n# for moving data to device (CPU or GPU)\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# for loading in the device (GPU if available else CPU)\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n        \n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:29.656577Z","iopub.execute_input":"2022-09-26T21:56:29.656964Z","iopub.status.idle":"2022-09-26T21:56:29.666563Z","shell.execute_reply.started":"2022-09-26T21:56:29.656931Z","shell.execute_reply":"2022-09-26T21:56:29.665390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:32.048037Z","iopub.execute_input":"2022-09-26T21:56:32.048979Z","iopub.status.idle":"2022-09-26T21:56:32.056273Z","shell.execute_reply.started":"2022-09-26T21:56:32.048941Z","shell.execute_reply":"2022-09-26T21:56:32.055107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:35.287705Z","iopub.execute_input":"2022-09-26T21:56:35.288099Z","iopub.status.idle":"2022-09-26T21:56:35.293581Z","shell.execute_reply.started":"2022-09-26T21:56:35.288037Z","shell.execute_reply":"2022-09-26T21:56:35.292119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        return self.relu2(out) + x # ReLU can be applied before or after adding the input","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:41.074974Z","iopub.execute_input":"2022-09-26T21:56:41.075701Z","iopub.status.idle":"2022-09-26T21:56:41.083142Z","shell.execute_reply.started":"2022-09-26T21:56:41.075663Z","shell.execute_reply":"2022-09-26T21:56:41.081924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for calculating the accuracy\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\n# base class for the model\n# base class for the model\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        train_acc = accuracy(out, labels)\n        return loss\n    \n    def training_step_4_acc(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        train_acc = accuracy(out, labels)\n        return train_acc\n        \n        \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                   # Generate prediction\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        acc = accuracy(out, labels)          # Calculate accuracy\n        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n    \n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x[\"val_loss\"] for x in outputs]\n        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n        epoch_accuracy = torch.stack(batch_accuracy).mean()\n        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, train_accuracy: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['train_accuracy'], result['val_loss'], result['val_accuracy']))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:56:46.452914Z","iopub.execute_input":"2022-09-26T21:56:46.453949Z","iopub.status.idle":"2022-09-26T21:56:46.465806Z","shell.execute_reply.started":"2022-09-26T21:56:46.453909Z","shell.execute_reply":"2022-09-26T21:56:46.464757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-six-b\"></a>\n### ResNet-9 model implementation","metadata":{}},{"cell_type":"code","source":"# Architecture for training\n# convolution block with BatchNormalization\ndef ConvBlock(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool:\n        layers.append(nn.MaxPool2d(4))\n    return nn.Sequential(*layers)\n\n\n# resnet architecture \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_diseases):\n        super().__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 64)\n        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n        \n        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                       nn.Flatten(),\n                                       nn.Linear(512, num_diseases),\n                                       nn.Softmax(dim=1))\n        \n    def forward(self, xb): # xb is the loaded batch\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out        ","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:57:06.861351Z","iopub.execute_input":"2022-09-26T21:57:06.861732Z","iopub.status.idle":"2022-09-26T21:57:06.873986Z","shell.execute_reply.started":"2022-09-26T21:57:06.861701Z","shell.execute_reply":"2022-09-26T21:57:06.873115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining the model \nmodel = to_device(ResNet9(3, len(train.classes)), device) \nmodel","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:50:51.365019Z","iopub.execute_input":"2022-09-27T00:50:51.365751Z","iopub.status.idle":"2022-09-27T00:50:51.437292Z","shell.execute_reply.started":"2022-09-27T00:50:51.365712Z","shell.execute_reply":"2022-09-27T00:50:51.436137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#getting summary of the model\nINPUT_SHAPE = (3, 256, 256)\nprint(summary(model.cuda(), (INPUT_SHAPE)))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:50:56.013859Z","iopub.execute_input":"2022-09-27T00:50:56.014250Z","iopub.status.idle":"2022-09-27T00:50:56.034087Z","shell.execute_reply.started":"2022-09-27T00:50:56.014216Z","shell.execute_reply":"2022-09-27T00:50:56.033081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#functions for training the network, added my code\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \n\ndef fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, momentum=0, weight_decay=0,\n                 grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay, momentum)\n         \n    \n    # scheduler for one cycle learniing rate\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    \n    for epoch in range(epochs):\n        # Training\n        model.train()\n        train_losses = []\n        train_accuracies = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            t_acc = model.training_step_4_acc(batch)\n            train_losses.append(loss)\n            train_accuracies.append(t_acc)\n            loss.backward()\n            \n            \n            # gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n    \n        # validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['train_accuracy'] = torch.stack(train_accuracies).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n    return history\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:50:59.848759Z","iopub.execute_input":"2022-09-27T00:50:59.849542Z","iopub.status.idle":"2022-09-27T00:50:59.861655Z","shell.execute_reply.started":"2022-09-27T00:50:59.849500Z","shell.execute_reply":"2022-09-27T00:50:59.860592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:51:02.501679Z","iopub.execute_input":"2022-09-27T00:51:02.502049Z","iopub.status.idle":"2022-09-27T00:51:07.101576Z","shell.execute_reply.started":"2022-09-27T00:51:02.502017Z","shell.execute_reply":"2022-09-27T00:51:07.100376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-seven\"></a>\n## Hyperparamter tuning with Optuna","metadata":{}},{"cell_type":"markdown","source":"Code for hyperparameter tuning adapted from https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(param, model, train_loader, val_loader, trial):\n    torch.cuda.empty_cache()\n    history = []\n    \n    #optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    #opt_func = getattr(torch.optim, param['optimizer'])\n    optimizer = getattr(torch.optim, param['optimizer'])(model.parameters(), lr=param['initial_lr'], weight_decay=param['weight_decay'], momentum=param['momentum'])\n\n        \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, param['initial_lr'], epochs=param['epochs'], steps_per_epoch=len(train_loader))\n\n    for epoch in range(param['epochs']):\n        # Training\n        model.train()\n        train_losses = []\n        train_accuracies = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            t_acc = model.training_step_4_acc(batch)\n            train_losses.append(loss)\n            train_accuracies.append(t_acc)\n            loss.backward()\n            \n            # gradient clipping\n            if param['grad_clip']: \n                nn.utils.clip_grad_value_(model.parameters(), param['grad_clip'])\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        # validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['train_accuracy'] = torch.stack(train_accuracies).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        val_acc_last_epoch = history[-1]['val_accuracy'].item()   \n        \n        trial.report(val_acc_last_epoch, epoch)\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n        \n        return val_acc_last_epoch ","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:57:56.078431Z","iopub.execute_input":"2022-09-26T21:57:56.078816Z","iopub.status.idle":"2022-09-26T21:57:56.092981Z","shell.execute_reply.started":"2022-09-26T21:57:56.078783Z","shell.execute_reply":"2022-09-26T21:57:56.091776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params = {'initial_lr': trial.suggest_loguniform('initial_lr', 0.01, 0.06),\n              'optimizer': trial.suggest_categorical(\"optimizer\", [\"SGD\"]),\n              'weight_decay': trial.suggest_loguniform('weight_decay', 1e-4, 1e-1),\n              'grad_clip': trial.suggest_float('grad_clip', 0.1, 0.5),\n              'epochs' : trial.suggest_int('epochs', 8, 25), \n              'momentum' : trial.suggest_float('momentum', 0, 1),\n              }\n    \n    val_accuracy = train_and_evaluate(params, model, train_dl, valid_dl, trial)\n    return val_accuracy #train_and_evaluate(params, model, train_dl, valid_dl)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:57:57.001411Z","iopub.execute_input":"2022-09-26T21:57:57.002200Z","iopub.status.idle":"2022-09-26T21:57:57.009282Z","shell.execute_reply.started":"2022-09-26T21:57:57.002157Z","shell.execute_reply":"2022-09-26T21:57:57.008310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nstudy = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=60)","metadata":{"execution":{"iopub.status.busy":"2022-09-26T21:58:00.267961Z","iopub.execute_input":"2022-09-26T21:58:00.268649Z","iopub.status.idle":"2022-09-26T23:55:19.073893Z","shell.execute_reply.started":"2022-09-26T21:58:00.268612Z","shell.execute_reply":"2022-09-26T23:55:19.072707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_trial = study.best_trial\n\nfor key, value in best_trial.params.items():\n    print(\"{}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-09-26T23:58:40.288644Z","iopub.execute_input":"2022-09-26T23:58:40.289062Z","iopub.status.idle":"2022-09-26T23:58:40.298054Z","shell.execute_reply.started":"2022-09-26T23:58:40.289028Z","shell.execute_reply":"2022-09-26T23:58:40.297081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-seven-a\"></a>\n### Visualizing the hyperparameter tuning process","metadata":{}},{"cell_type":"code","source":"# optuna.visualization.plot_optimization_history(study)  #visualizing the tuning \noptuna.visualization.matplotlib.plot_optimization_history(study)\nplt.rcParams['figure.figsize']=[6,6]\nplt.rcParams['figure.facecolor'] = 'white'\nplt.tight_layout()\n#plt.savefig('/kaggle/working/opt_hist_plot.png', dpi=600, bbox_inches=\"tight\")\n#plt.savefig('/kaggle/working/gblurred_sample_imgs.png', dpi=600, bbox_inches=\"tight\")  #sample images and their corresponding andom rotations\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:09:15.936883Z","iopub.execute_input":"2022-09-27T00:09:15.937267Z","iopub.status.idle":"2022-09-27T00:09:16.267995Z","shell.execute_reply.started":"2022-09-27T00:09:15.937236Z","shell.execute_reply":"2022-09-27T00:09:16.267021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_param_importances(study) #visualizing the parameter importances  #what is the difference between this plot and the one below","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:09:21.949027Z","iopub.execute_input":"2022-09-27T00:09:21.949735Z","iopub.status.idle":"2022-09-27T00:09:22.555402Z","shell.execute_reply.started":"2022-09-27T00:09:21.949697Z","shell.execute_reply":"2022-09-27T00:09:22.554461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.matplotlib.plot_param_importances(study) #i can modify the plot\nplt.tight_layout()\nplt.rcParams['figure.figsize']=[6,6]\n#plt.savefig('/kaggle/working/hyparam_importances_plot.png', dpi=600, bbox_inches=\"tight\")\n#plt.grid(color='#EAE4E3')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:12:13.948136Z","iopub.execute_input":"2022-09-27T00:12:13.949114Z","iopub.status.idle":"2022-09-27T00:12:14.586221Z","shell.execute_reply.started":"2022-09-27T00:12:13.949042Z","shell.execute_reply":"2022-09-27T00:12:14.585325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.matplotlib.plot_contour","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:12:18.774835Z","iopub.execute_input":"2022-09-27T00:12:18.775224Z","iopub.status.idle":"2022-09-27T00:12:18.783236Z","shell.execute_reply.started":"2022-09-27T00:12:18.775190Z","shell.execute_reply":"2022-09-27T00:12:18.781912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.matplotlib.plot_edf(study)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:12:19.106588Z","iopub.execute_input":"2022-09-27T00:12:19.106936Z","iopub.status.idle":"2022-09-27T00:12:19.311694Z","shell.execute_reply.started":"2022-09-27T00:12:19.106907Z","shell.execute_reply":"2022-09-27T00:12:19.310799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------","metadata":{"execution":{"iopub.status.busy":"2022-07-26T05:03:50.519722Z","iopub.execute_input":"2022-07-26T05:03:50.520435Z","iopub.status.idle":"2022-07-26T05:03:50.555171Z","shell.execute_reply.started":"2022-07-26T05:03:50.52037Z","shell.execute_reply":"2022-07-26T05:03:50.551821Z"}}},{"cell_type":"markdown","source":"<a id=\"section-eight\"></a>\n## ResNet-9 model training with optimized hyperparameters","metadata":{}},{"cell_type":"code","source":"epochs = 11\nmomentum = 0.9\ngrad_clip = 0.407\ninitial_lr = 0.0103\nweight_decay = 0.0128\nopt_func = torch.optim.SGD\n\nhistory = fit_OneCycle(epochs, initial_lr, model, train_dl, valid_dl, \n                       momentum=0.9, \n                       grad_clip=0.407, \n                       weight_decay=0.0128, \n                       opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:51:27.936281Z","iopub.execute_input":"2022-09-27T00:51:27.936667Z","iopub.status.idle":"2022-09-27T01:12:59.508705Z","shell.execute_reply.started":"2022-09-27T00:51:27.936634Z","shell.execute_reply":"2022-09-27T01:12:59.507160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-nine\"></a>\n## Plotting training accuracies and losses","metadata":{}},{"cell_type":"code","source":"def plot_accuracies(history, epochs):\n    \"\"\"This function plots both training and validation accuracies of ResNet-9 model\"\"\"\n    plt.rcParams['figure.figsize'] = [8, 8]\n    epochs = [i for i in range(1, epochs+1)]\n    val_accuracies = [x['val_accuracy'] for x in history]\n    train_accuracies = [x['train_accuracy'] for x in history]\n    plt.plot(epochs, train_accuracies, '-o', color='blue', label='train_loss')\n    plt.plot(epochs, val_accuracies, '-o', color='green', label='validation_loss')\n    plt.xticks(np.arange(min(epochs), max(epochs)+1, 1.0))\n    plt.xlabel('Epochs', size=13)\n    plt.ylabel('Accuracies', size=13)\n    plt.grid(color='#EAE4E3')\n    #plt.xticks(rotation=90)\n    plt.title('Training and validation accuracies of ResNet-9', size=13)\n    plt.legend()\n    plt.savefig('../working/resnet9-tv-accuracies.png', dpi=600,  bbox_inches=\"tight\")\n    plt.show()\n    \ndef plot_losses(history, epochs):\n    plt.rcParams['figure.figsize'] = [8, 8]\n    epochs = [i for i in range(1, epochs+1)]\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x.get('val_loss').cpu().numpy() for x in history]\n    plt.plot(epochs, train_losses, '-o', color='blue', label='train_loss')\n    plt.plot(epochs, val_losses, '-o', color='green', label='validation_loss')\n    plt.xticks(np.arange(min(epochs), max(epochs)+1, 1.0))\n    plt.xlabel('Epochs', size=13)\n    plt.ylabel('Losses', size=13)\n    plt.grid(color='#EAE4E3')\n    #plt.xticks(rotation=90)\n    plt.title('Training and validation losses of ResNet-9', size=13)\n    plt.legend()\n    plt.savefig('../working/resnet9-tv-losses.png', dpi=600,  bbox_inches=\"tight\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T00:48:10.610557Z","iopub.execute_input":"2022-09-27T00:48:10.610925Z","iopub.status.idle":"2022-09-27T00:48:10.624627Z","shell.execute_reply.started":"2022-09-27T00:48:10.610892Z","shell.execute_reply":"2022-09-27T00:48:10.623563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-nine-a\"></a>\n### Accuracies","metadata":{}},{"cell_type":"code","source":"#Validation accuracy\nplot_accuracies(history, 11)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:13:45.309654Z","iopub.execute_input":"2022-09-27T01:13:45.310088Z","iopub.status.idle":"2022-09-27T01:13:47.283530Z","shell.execute_reply.started":"2022-09-27T01:13:45.310027Z","shell.execute_reply":"2022-09-27T01:13:47.282113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-nine-b\"></a>\n### Losses","metadata":{}},{"cell_type":"code","source":"#Validation loss\nplot_losses(history, 11)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:13:54.832624Z","iopub.execute_input":"2022-09-27T01:13:54.833041Z","iopub.status.idle":"2022-09-27T01:13:56.685901Z","shell.execute_reply.started":"2022-09-27T01:13:54.833003Z","shell.execute_reply":"2022-09-27T01:13:56.684974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-ten\"></a>\n## Test data ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-ten-a\"></a>\n### Test data preparation","metadata":{"execution":{"iopub.status.busy":"2022-09-11T18:37:21.318736Z","iopub.execute_input":"2022-09-11T18:37:21.319242Z","iopub.status.idle":"2022-09-11T18:37:21.334423Z","shell.execute_reply.started":"2022-09-11T18:37:21.319208Z","shell.execute_reply":"2022-09-11T18:37:21.332791Z"}}},{"cell_type":"code","source":"###Creating a new test dir because there was an svn file or folder found in the test dir\nos.mkdir('../test_data')\nos.mkdir('../test_data/test')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:18.700878Z","iopub.execute_input":"2022-09-27T01:18:18.701265Z","iopub.status.idle":"2022-09-27T01:18:18.707044Z","shell.execute_reply.started":"2022-09-27T01:18:18.701234Z","shell.execute_reply":"2022-09-27T01:18:18.705906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir_old = test_dir\ntest_dir_new = '../test_data'\nprint(test_dir_old)\nprint(test_dir_new)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:20.032600Z","iopub.execute_input":"2022-09-27T01:18:20.032978Z","iopub.status.idle":"2022-09-27T01:18:20.038933Z","shell.execute_reply.started":"2022-09-27T01:18:20.032946Z","shell.execute_reply":"2022-09-27T01:18:20.037796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir_old","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:22.042983Z","iopub.execute_input":"2022-09-27T01:18:22.043746Z","iopub.status.idle":"2022-09-27T01:18:22.051299Z","shell.execute_reply.started":"2022-09-27T01:18:22.043706Z","shell.execute_reply":"2022-09-27T01:18:22.050003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\nfor f in os.listdir(f'{test_dir_new}/test'):\n    os.remove(f'{test_dir_new}/test/{f}')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:22.460731Z","iopub.execute_input":"2022-09-27T01:18:22.461116Z","iopub.status.idle":"2022-09-27T01:18:22.466749Z","shell.execute_reply.started":"2022-09-27T01:18:22.461078Z","shell.execute_reply":"2022-09-27T01:18:22.465656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(f'{test_dir_new}/test')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:26.953567Z","iopub.execute_input":"2022-09-27T01:18:26.953945Z","iopub.status.idle":"2022-09-27T01:18:26.960603Z","shell.execute_reply.started":"2022-09-27T01:18:26.953913Z","shell.execute_reply":"2022-09-27T01:18:26.959585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for theclass in train.classes:\n#     print(f\"{test_dir_new}/test/{theclass}\")\n    os.mkdir(f\"{test_dir_new}/test/{theclass}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:30.790419Z","iopub.execute_input":"2022-09-27T01:18:30.790808Z","iopub.status.idle":"2022-09-27T01:18:30.796575Z","shell.execute_reply.started":"2022-09-27T01:18:30.790775Z","shell.execute_reply":"2022-09-27T01:18:30.795546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(f'{test_dir_new}/test')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:18:34.263654Z","iopub.execute_input":"2022-09-27T01:18:34.264585Z","iopub.status.idle":"2022-09-27T01:18:34.272767Z","shell.execute_reply.started":"2022-09-27T01:18:34.264534Z","shell.execute_reply":"2022-09-27T01:18:34.271671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'tomato_late_23.JPG'.split('_')[1] + '_blight'","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:27:33.684311Z","iopub.execute_input":"2022-09-27T01:27:33.684689Z","iopub.status.idle":"2022-09-27T01:27:33.691129Z","shell.execute_reply.started":"2022-09-27T01:27:33.684657Z","shell.execute_reply":"2022-09-27T01:27:33.690126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(f'{test_dir_new}/test')","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:26:20.014284Z","iopub.execute_input":"2022-09-27T01:26:20.014656Z","iopub.status.idle":"2022-09-27T01:26:20.022625Z","shell.execute_reply.started":"2022-09-27T01:26:20.014624Z","shell.execute_reply":"2022-09-27T01:26:20.021361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Moving file from old test dir to new test dir\nnum_moved = 0\nfor img in os.listdir(test_dir_old+'/test'):\n    if img.endswith('.JPG'):\n        if img.split('_')[1] !='healthy':\n            theclass = img.split('_')[1] + '_blight'\n            #print(theclass)\n            shutil.copy(f\"{test_dir_old+'/test/'}{img}\", f\"{test_dir_new+'/test/'+theclass+'/'+img}\")\n        \n        elif img.split('_')[1] =='healthy':\n            theclass = img.split('_')[1] \n            #print(theclass)\n            shutil.copy(f\"{test_dir_old+'/test/'}{img}\", f\"{test_dir_new+'/test/'+theclass+'/'+img}\")\n        \n        num_moved += 1\n    elif img.endswith('svn'):\n        print('not going to move you!')\nprint(f\"Number of files moved: {num_moved}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:29:38.286827Z","iopub.execute_input":"2022-09-27T01:29:38.287231Z","iopub.status.idle":"2022-09-27T01:29:45.507270Z","shell.execute_reply.started":"2022-09-27T01:29:38.287198Z","shell.execute_reply":"2022-09-27T01:29:45.506152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir(f'{test_dir_new}/test')) #3 folders which are early_blight, healthy and late_blight","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:25.102826Z","iopub.execute_input":"2022-09-27T01:30:25.103206Z","iopub.status.idle":"2022-09-27T01:30:25.110799Z","shell.execute_reply.started":"2022-09-27T01:30:25.103174Z","shell.execute_reply":"2022-09-27T01:30:25.109726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('../test_data/test')) #files have been moved","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:29.202859Z","iopub.execute_input":"2022-09-27T01:30:29.203255Z","iopub.status.idle":"2022-09-27T01:30:29.209945Z","shell.execute_reply.started":"2022-09-27T01:30:29.203222Z","shell.execute_reply":"2022-09-27T01:30:29.208977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(f\"{test_dir_new}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:36.201846Z","iopub.execute_input":"2022-09-27T01:30:36.202238Z","iopub.status.idle":"2022-09-27T01:30:36.209488Z","shell.execute_reply.started":"2022-09-27T01:30:36.202205Z","shell.execute_reply":"2022-09-27T01:30:36.208387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing model on test data\ntest = ImageFolder('../test_data/test', transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:43.070470Z","iopub.execute_input":"2022-09-27T01:30:43.070859Z","iopub.status.idle":"2022-09-27T01:30:43.087598Z","shell.execute_reply.started":"2022-09-27T01:30:43.070825Z","shell.execute_reply":"2022-09-27T01:30:43.086293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:46.405907Z","iopub.execute_input":"2022-09-27T01:30:46.406385Z","iopub.status.idle":"2022-09-27T01:30:46.413408Z","shell.execute_reply.started":"2022-09-27T01:30:46.406346Z","shell.execute_reply":"2022-09-27T01:30:46.412316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = sorted(os.listdir(test_dir_new + '/test')) # since images in test folder are not in alphabetical order\n#test_images","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:30:50.950688Z","iopub.execute_input":"2022-09-27T01:30:50.951101Z","iopub.status.idle":"2022-09-27T01:30:50.956575Z","shell.execute_reply.started":"2022-09-27T01:30:50.951037Z","shell.execute_reply":"2022-09-27T01:30:50.955590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:31:00.330483Z","iopub.execute_input":"2022-09-27T01:31:00.330878Z","iopub.status.idle":"2022-09-27T01:31:00.338541Z","shell.execute_reply.started":"2022-09-27T01:31:00.330843Z","shell.execute_reply":"2022-09-27T01:31:00.337196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    \"\"\"Converts image to array and return the predicted class\n        with highest probability\"\"\"\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n\n    return train.classes[preds[0].item()]","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:31:10.263409Z","iopub.execute_input":"2022-09-27T01:31:10.263785Z","iopub.status.idle":"2022-09-27T01:31:10.270184Z","shell.execute_reply.started":"2022-09-27T01:31:10.263752Z","shell.execute_reply":"2022-09-27T01:31:10.268832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:31:12.631822Z","iopub.execute_input":"2022-09-27T01:31:12.632200Z","iopub.status.idle":"2022-09-27T01:31:12.638569Z","shell.execute_reply.started":"2022-09-27T01:31:12.632168Z","shell.execute_reply":"2022-09-27T01:31:12.637512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = test[-1]\nlabel","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:31:14.794388Z","iopub.execute_input":"2022-09-27T01:31:14.794754Z","iopub.status.idle":"2022-09-27T01:31:14.807068Z","shell.execute_reply.started":"2022-09-27T01:31:14.794723Z","shell.execute_reply":"2022-09-27T01:31:14.805988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_images))\nprint(len(test))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:31:18.155970Z","iopub.execute_input":"2022-09-27T01:31:18.156467Z","iopub.status.idle":"2022-09-27T01:31:18.168429Z","shell.execute_reply.started":"2022-09-27T01:31:18.156418Z","shell.execute_reply":"2022-09-27T01:31:18.166913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-ten-b\"></a>\n### ResNet-9 model evaluation on test data","metadata":{}},{"cell_type":"code","source":"# predicting first image\nimg, label = test[-1000]\nplt.imshow(img.permute(1, 2, 0))\n# print('Label:', test_images[-1000], ', Predicted:', predict_image(img, model))\nprint('Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:32:53.817606Z","iopub.execute_input":"2022-09-27T01:32:53.817977Z","iopub.status.idle":"2022-09-27T01:32:54.237058Z","shell.execute_reply.started":"2022-09-27T01:32:53.817943Z","shell.execute_reply":"2022-09-27T01:32:54.236111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader_r = torch.utils.data.DataLoader(test, \n                                            batch_size=batch_size,\n                                            shuffle=True)\n\ntest_loader_r = DeviceDataLoader(test_loader_r, device)\ntest_loader_r","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:32:59.585127Z","iopub.execute_input":"2022-09-27T01:32:59.585529Z","iopub.status.idle":"2022-09-27T01:32:59.593304Z","shell.execute_reply.started":"2022-09-27T01:32:59.585494Z","shell.execute_reply":"2022-09-27T01:32:59.591981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions =[] #code adapted from https://stackoverflow.com/questions/63647547/how-to-find-confusion-matrix-and-plot-it-for-image-classifier-in-pytorch\ntargets = []\nfor images, labels in test_loader_r:\n    images, labels = images.cuda(), labels.cuda()\n    logps = model(images)\n    output = torch.exp(logps)\n    pred = torch.argmax(output, 1)\n\n    # convert to numpy arrays\n    pred = pred.detach().cpu().numpy()\n    labels = labels.detach().cpu().numpy()\n    \n    for i in range(len(pred)):\n        predictions.append(pred[i])\n        targets.append(labels[i])","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:02.774160Z","iopub.execute_input":"2022-09-27T01:33:02.774536Z","iopub.status.idle":"2022-09-27T01:33:09.067804Z","shell.execute_reply.started":"2022-09-27T01:33:02.774505Z","shell.execute_reply":"2022-09-27T01:33:09.066740Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.classes","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:12.713552Z","iopub.execute_input":"2022-09-27T01:33:12.713925Z","iopub.status.idle":"2022-09-27T01:33:12.722163Z","shell.execute_reply.started":"2022-09-27T01:33:12.713894Z","shell.execute_reply":"2022-09-27T01:33:12.720413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets[:5]","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:14.644949Z","iopub.execute_input":"2022-09-27T01:33:14.645344Z","iopub.status.idle":"2022-09-27T01:33:14.652036Z","shell.execute_reply.started":"2022-09-27T01:33:14.645308Z","shell.execute_reply":"2022-09-27T01:33:14.651058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[:5]","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:18.328782Z","iopub.execute_input":"2022-09-27T01:33:18.329185Z","iopub.status.idle":"2022-09-27T01:33:18.336703Z","shell.execute_reply.started":"2022-09-27T01:33:18.329150Z","shell.execute_reply":"2022-09-27T01:33:18.335505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-ten-bi\"></a>\n#### Confusion matrix","metadata":{}},{"cell_type":"code","source":"cf_matrix = confusion_matrix(targets, predictions)\ncf_matrix","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:21.586214Z","iopub.execute_input":"2022-09-27T01:33:21.587144Z","iopub.status.idle":"2022-09-27T01:33:21.599805Z","shell.execute_reply.started":"2022-09-27T01:33:21.587098Z","shell.execute_reply":"2022-09-27T01:33:21.598617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = train.classes\ndataframe = pd.DataFrame(cf_matrix, index=class_names, columns=class_names)\ndataframe","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:22.982469Z","iopub.execute_input":"2022-09-27T01:33:22.982832Z","iopub.status.idle":"2022-09-27T01:33:22.997048Z","shell.execute_reply.started":"2022-09-27T01:33:22.982801Z","shell.execute_reply":"2022-09-27T01:33:22.996098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 6))  #change size to 4, 4?\n\n#Create heatmap\nsns.heatmap(dataframe, annot=True, cbar=True,cmap=\"OrRd\",fmt=\"d\") #'purples', 'PuRd'\nplt.title(\"Confusion Matrix for ResNet-9 model\", size=12), plt.tight_layout()\n \nplt.ylabel(\"Actual Class\", size=12), \nplt.xlabel(\"Predicted Class\",  size=12)\nplt.tight_layout()\n#plt.savefig('../working/cmatrxresnet9.png', dpi=600,  bbox_inches=\"tight\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:28.318555Z","iopub.execute_input":"2022-09-27T01:33:28.319346Z","iopub.status.idle":"2022-09-27T01:33:28.733503Z","shell.execute_reply.started":"2022-09-27T01:33:28.319301Z","shell.execute_reply":"2022-09-27T01:33:28.732460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"subsection-ten-bii\"></a>\n#### Test accuracy and classification report","metadata":{}},{"cell_type":"code","source":"print(\"Test Accuracy : {}\".format(accuracy_score(targets, predictions)))\nprint(\"\\nConfusion Matrix : \")\nprint(confusion_matrix(targets, predictions))\nprint(\"\\nClassification Report :\")\nprint(classification_report(targets, predictions, target_names=train.classes))","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:33.041054Z","iopub.execute_input":"2022-09-27T01:33:33.041681Z","iopub.status.idle":"2022-09-27T01:33:33.059449Z","shell.execute_reply.started":"2022-09-27T01:33:33.041643Z","shell.execute_reply":"2022-09-27T01:33:33.058303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"section-eleven\"></a>\n## Saving the model","metadata":{}},{"cell_type":"code","source":"# saving to the kaggle working directory ###check this again\nPATH1 = './resnet9-mdlsd.pth'  \ntorch.save(model.state_dict(), PATH1)\n\nPATH2 = './resnet9-mdl.pth' \ntorch.save(model, PATH2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---------------------------------","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-twelve\"></a>\n## Model Explanations (DeepShap and Saliency Maps)","metadata":{}},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:58.766527Z","iopub.execute_input":"2022-09-27T01:33:58.766904Z","iopub.status.idle":"2022-09-27T01:33:58.771729Z","shell.execute_reply.started":"2022-09-27T01:33:58.766870Z","shell.execute_reply":"2022-09-27T01:33:58.770775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader_r = torch.utils.data.DataLoader(test, \n                                            batch_size=batch_size,\n                                            shuffle=True)\n\ntest_loader_r = DeviceDataLoader(test_loader_r, device)\ntest_loader_r","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:33:59.408888Z","iopub.execute_input":"2022-09-27T01:33:59.409341Z","iopub.status.idle":"2022-09-27T01:33:59.417909Z","shell.execute_reply.started":"2022-09-27T01:33:59.409303Z","shell.execute_reply":"2022-09-27T01:33:59.416993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since shuffle=True, this is a random sample of test data\nimages, targets =  next(iter(test_loader_r))\nBACKGROUND_SIZE = 20\nbackground_images = images[:BACKGROUND_SIZE]\nbackground_targets = targets[:BACKGROUND_SIZE].cpu().numpy()\n#increase the size after you've fixed everything \n\ntest_images = images[BACKGROUND_SIZE:BACKGROUND_SIZE+9]\ntest_targets = targets[BACKGROUND_SIZE:BACKGROUND_SIZE+9].cpu().numpy()\ndef show_attributions(model):\n    # predict the probabilities of the digits using the test images\n    output = model(test_images.to(device))\n    # get the index of the max log-probability\n    pred = output.max(1, keepdim=True)[1] \n    # convert to numpy only once to save time\n    pred_np = pred.cpu().numpy() \n\n    expl = shap.DeepExplainer(model, background_images)\n    train_classes = ['early_blight', 'healthy', 'late_blight']\n    for i in range(0, len(test_images)):\n        warnings.filterwarnings('ignore')\n        \n        torch.cuda.empty_cache()\n        ti = test_images[[i]]\n        sv = expl.shap_values(ti)\n        sn = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in sv]\n        tn = np.swapaxes(np.swapaxes(ti.cpu().numpy(), 1, -1), 1, 2) #.cpu().numpy()?\n\n        # Prepare the attribution plot, but do not draw it yet\n        # We will add more info to the plots later in the code\n        shap.image_plot(sn, -tn, show=False)\n\n        # Prepare to augment the plot\n        fig = plt.gcf()\n        allaxes = fig.get_axes()\n\n        allaxes[0].set_title('Actual: {}, Pred: {}'.format(train_classes[test_targets[i]], train_classes[pred_np[i][0]]), fontsize=10)\n        \n        \n        prob = output[i].detach().cpu().numpy()\n        for x in range(1, len(allaxes)-1):\n            #allaxes[x].set_title('{}'.format(train_classes[x-1]), fontsize=10)\n            allaxes[x].set_title('{}({:.2%})'.format(train_classes[x-1], prob[x-1]), fontsize=10)\n            allaxes[0].imshow(test_images[i].cpu().permute(1, 2, 0))       \n         \n\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:34:41.425488Z","iopub.execute_input":"2022-09-27T01:34:41.425857Z","iopub.status.idle":"2022-09-27T01:34:41.518208Z","shell.execute_reply.started":"2022-09-27T01:34:41.425824Z","shell.execute_reply":"2022-09-27T01:34:41.517226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_attributions = show_attributions(model)\nfeature_attributions","metadata":{"execution":{"iopub.status.busy":"2022-09-27T01:34:42.610053Z","iopub.execute_input":"2022-09-27T01:34:42.610455Z","iopub.status.idle":"2022-09-27T01:34:43.234359Z","shell.execute_reply.started":"2022-09-27T01:34:42.610423Z","shell.execute_reply":"2022-09-27T01:34:43.233004Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
