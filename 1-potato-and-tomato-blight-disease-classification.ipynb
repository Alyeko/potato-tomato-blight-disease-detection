{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook contains...","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:51:29.443322Z","iopub.execute_input":"2022-08-03T17:51:29.443984Z","iopub.status.idle":"2022-08-03T17:51:43.429537Z","shell.execute_reply.started":"2022-08-03T17:51:29.443831Z","shell.execute_reply":"2022-08-03T17:51:43.427984Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os                                      # for working with files\nimport sys\nimport shap                                    # for checking feature importances\nimport torch                                   # Pytorch module \nimport shutil\nimport optuna\nimport warnings\nimport numpy as np                             # for numerical computationss\nimport pandas as pd                            # for working with dataframes\nimport torch.nn as nn                          # for creating  neural networks\nfrom PIL import Image                          # for checking images\nimport matplotlib.pyplot as plt                # for plotting informations on graph and images using tensors\nimport torch.nn.functional as F                # for functions for calculating loss\nfrom torchsummary import summary               # for getting the summary of our model\nfrom torchvision.utils import make_grid        # for data checking\nfrom torch.utils.data import DataLoader        # for dataloaders \nimport torchvision.transforms as transforms    # for transforming images into tensors \nfrom torchvision.datasets import ImageFolder   # for working with classes and images\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:51:43.432903Z","iopub.execute_input":"2022-08-03T17:51:43.433215Z","iopub.status.idle":"2022-08-03T17:51:48.838944Z","shell.execute_reply.started":"2022-08-03T17:51:43.433185Z","shell.execute_reply":"2022-08-03T17:51:48.837447Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Data exploration!","metadata":{}},{"cell_type":"code","source":"os.listdir('/kaggle/input/dataset/idata/Image Dataset/ImageDataset/')","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:26.307418Z","iopub.execute_input":"2022-08-03T17:52:26.308563Z","iopub.status.idle":"2022-08-03T17:52:26.335093Z","shell.execute_reply.started":"2022-08-03T17:52:26.308481Z","shell.execute_reply":"2022-08-03T17:52:26.333668Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/dataset/idata/Image Dataset/ImageDataset/'","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:26.520803Z","iopub.execute_input":"2022-08-03T17:52:26.521283Z","iopub.status.idle":"2022-08-03T17:52:26.527238Z","shell.execute_reply.started":"2022-08-03T17:52:26.521253Z","shell.execute_reply":"2022-08-03T17:52:26.525425Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# print(f\"Number of image directories are {len(os.listdir(data_fpath))+len(os.listdir('/kaggle/input/newds/ImageDataset_new/ImageDataset_new/'))}\\n\")\nprint('Number of unique plants are 2, potato and tomato\\n')\nprint('Number of diseases are 4, early and late blight disease for tomato, early and late blight for potato\\n')","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:26.777923Z","iopub.execute_input":"2022-08-03T17:52:26.779173Z","iopub.status.idle":"2022-08-03T17:52:26.788238Z","shell.execute_reply.started":"2022-08-03T17:52:26.779120Z","shell.execute_reply":"2022-08-03T17:52:26.784962Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_dir","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:26.966652Z","iopub.execute_input":"2022-08-03T17:52:26.967846Z","iopub.status.idle":"2022-08-03T17:52:26.979955Z","shell.execute_reply.started":"2022-08-03T17:52:26.967783Z","shell.execute_reply":"2022-08-03T17:52:26.978069Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_dir = data_dir + \"train/\"\nvalid_dir = data_dir + \"valid/\"\n# test_dir\ndiseases_tr = os.listdir(train_dir)\ndiseases_va = os.listdir(valid_dir)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:29.384551Z","iopub.execute_input":"2022-08-03T17:52:29.385016Z","iopub.status.idle":"2022-08-03T17:52:29.399158Z","shell.execute_reply.started":"2022-08-03T17:52:29.384984Z","shell.execute_reply":"2022-08-03T17:52:29.397679Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"valid_dir","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:30.131329Z","iopub.execute_input":"2022-08-03T17:52:30.131753Z","iopub.status.idle":"2022-08-03T17:52:30.142413Z","shell.execute_reply.started":"2022-08-03T17:52:30.131721Z","shell.execute_reply":"2022-08-03T17:52:30.140849Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"diseases_tr","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:31.184745Z","iopub.execute_input":"2022-08-03T17:52:31.185170Z","iopub.status.idle":"2022-08-03T17:52:31.194451Z","shell.execute_reply.started":"2022-08-03T17:52:31.185124Z","shell.execute_reply":"2022-08-03T17:52:31.192993Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"plants = []\nNumberOfDiseases = 0\nfor plant in diseases_tr:\n    if plant.split('___')[0] not in plants:\n        plants.append(plant.split('___')[0])\n    if plant.split('_')[1] != 'healthy':\n        NumberOfDiseases += 1","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:33.735518Z","iopub.execute_input":"2022-08-03T17:52:33.735949Z","iopub.status.idle":"2022-08-03T17:52:33.744654Z","shell.execute_reply.started":"2022-08-03T17:52:33.735917Z","shell.execute_reply":"2022-08-03T17:52:33.743162Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Number of images for each clas in the training data\nnums_train = {}\nfor folder in sorted(os.listdir(f\"{data_dir}/train\")):\n    nums_train[folder] = len(os.listdir(f\"/{data_dir}/train/{folder}\"))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_training_class = pd.DataFrame(nums_train.values(), index=nums_train.keys(), columns=[\"no. of images\"])\nimg_per_training_class","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:36.219469Z","iopub.execute_input":"2022-08-03T17:52:36.220257Z","iopub.status.idle":"2022-08-03T17:52:37.692738Z","shell.execute_reply.started":"2022-08-03T17:52:36.220223Z","shell.execute_reply":"2022-08-03T17:52:37.691395Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Number of images for each clas in the training data\nnums_valid = {}\nfor folder in sorted(os.listdir(f\"{data_dir}/valid\")):\n    nums_valid[folder] = len(os.listdir(f\"{data_dir}/valid/{folder}\"))\n    \n# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n\nimg_per_valid_class = pd.DataFrame(nums_valid.values(), index=nums_valid.keys(), columns=[\"no. of images\"])\nimg_per_valid_class","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:37.695241Z","iopub.execute_input":"2022-08-03T17:52:37.697217Z","iopub.status.idle":"2022-08-03T17:52:38.838863Z","shell.execute_reply.started":"2022-08-03T17:52:37.697185Z","shell.execute_reply":"2022-08-03T17:52:38.837380Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#changes the text on matplotlib plots to the computer modern font style\nfrom matplotlib import font_manager\nfont_path = '../input/compumodern/cmu.serif-roman.ttf'\nfont_manager.fontManager.addfont(font_path)\nprop = font_manager.FontProperties(fname=font_path)\n\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = prop.get_name()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:41.463409Z","iopub.execute_input":"2022-08-03T17:52:41.463817Z","iopub.status.idle":"2022-08-03T17:52:41.483288Z","shell.execute_reply.started":"2022-08-03T17:52:41.463787Z","shell.execute_reply":"2022-08-03T17:52:41.482049Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# plotting number of images available for each class\nindex = [n for n in range(6)]\nplt.figure(figsize=(8, 6))\nplt.bar(index, [n for n in nums_train.values()], color='#8528B0', width=0.7, align='center')\nplt.xlabel('Classes', fontsize=15)\nplt.ylabel('No of images', fontsize=15)\nplt.xticks(index, [key for key in nums_train.keys()], fontsize=15, rotation=90)\nplt.title('Images per class for training dataset', fontsize=15)\n\nplt.savefig('/kaggle/working/number_imgs_training.png', dpi=600, bbox_inches=\"tight\")  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:42.249185Z","iopub.execute_input":"2022-08-03T17:52:42.249830Z","iopub.status.idle":"2022-08-03T17:52:44.474199Z","shell.execute_reply.started":"2022-08-03T17:52:42.249771Z","shell.execute_reply":"2022-08-03T17:52:44.472695Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# plotting number of images available for each class\nindex = [n for n in range(6)]\nplt.figure(figsize=(8, 6))\nplt.bar(index, [n for n in nums_valid.values()], color='#8528B0', width=0.7) \nplt.xlabel('Classes', fontsize=15)\nplt.ylabel('No of images', fontsize=15)\nplt.xticks(index, [key for key in nums_valid.keys()], fontsize=15, rotation=90)\nplt.title('Images per class for validation dataset', fontsize=15)\n# plt.tight_layout()\nplt.savefig('/kaggle/working/number_imgs_validation.png', dpi=600, bbox_inches=\"tight\")  \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:44.476745Z","iopub.execute_input":"2022-08-03T17:52:44.477895Z","iopub.status.idle":"2022-08-03T17:52:46.333318Z","shell.execute_reply.started":"2022-08-03T17:52:44.477830Z","shell.execute_reply":"2022-08-03T17:52:46.331698Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"The data has already been augmented. see https://github.com/Alyeko/potato-tomato-blight-disease-detection","metadata":{"execution":{"iopub.status.busy":"2022-07-08T19:53:01.18532Z","iopub.execute_input":"2022-07-08T19:53:01.185753Z","iopub.status.idle":"2022-07-08T19:53:01.192473Z","shell.execute_reply.started":"2022-07-08T19:53:01.185709Z","shell.execute_reply":"2022-07-08T19:53:01.191217Z"}}},{"cell_type":"markdown","source":"### Images available for training","metadata":{}},{"cell_type":"code","source":"n_train = 0\nfor value in nums_train.values():\n    n_train += value\nprint(f\"There are {n_train} images for training\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:51.722767Z","iopub.execute_input":"2022-08-03T17:52:51.723877Z","iopub.status.idle":"2022-08-03T17:52:51.731966Z","shell.execute_reply.started":"2022-08-03T17:52:51.723843Z","shell.execute_reply":"2022-08-03T17:52:51.730086Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"n_valid = 0\nfor value in nums_valid.values():\n    n_valid += value\nprint(f\"There are {n_valid} images for validation\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:52.478741Z","iopub.execute_input":"2022-08-03T17:52:52.479139Z","iopub.status.idle":"2022-08-03T17:52:52.487717Z","shell.execute_reply.started":"2022-08-03T17:52:52.479094Z","shell.execute_reply":"2022-08-03T17:52:52.486290Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Checking if here are non img files in the training data folder\n","metadata":{}},{"cell_type":"code","source":"folds = [folder for folder in os.listdir(train_dir)]\nfolds","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:55.626587Z","iopub.execute_input":"2022-08-03T17:52:55.627067Z","iopub.status.idle":"2022-08-03T17:52:55.639556Z","shell.execute_reply.started":"2022-08-03T17:52:55.627034Z","shell.execute_reply":"2022-08-03T17:52:55.636805Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for i in folds:\n    for img in os.listdir(train_dir+i):\n        if not img.endswith('.JPG'):\n            print('yes!')","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:57.620127Z","iopub.execute_input":"2022-08-03T17:52:57.620555Z","iopub.status.idle":"2022-08-03T17:52:57.647845Z","shell.execute_reply.started":"2022-08-03T17:52:57.620525Z","shell.execute_reply":"2022-08-03T17:52:57.646304Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for i in folds:\n    for img in os.listdir(valid_dir+i):\n        if not img.endswith('.JPG'):\n            print('yes!')","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:52:58.104529Z","iopub.execute_input":"2022-08-03T17:52:58.105887Z","iopub.status.idle":"2022-08-03T17:52:58.121444Z","shell.execute_reply.started":"2022-08-03T17:52:58.105843Z","shell.execute_reply":"2022-08-03T17:52:58.119968Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_dir","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:00.205457Z","iopub.execute_input":"2022-08-03T17:53:00.206889Z","iopub.status.idle":"2022-08-03T17:53:00.217715Z","shell.execute_reply.started":"2022-08-03T17:53:00.206840Z","shell.execute_reply":"2022-08-03T17:53:00.215219Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(f\"There are {len(os.listdir('/kaggle/input/dataset/idata/Image Dataset/test_data/test'))} images for test\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:00.786797Z","iopub.execute_input":"2022-08-03T17:53:00.787236Z","iopub.status.idle":"2022-08-03T17:53:01.169378Z","shell.execute_reply.started":"2022-08-03T17:53:00.787201Z","shell.execute_reply":"2022-08-03T17:53:01.167698Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(f\"Training dir: {os.listdir('/kaggle/input/dataset/idata/Image Dataset/ImageDataset/')}\")\nprint(f\"All: {os.listdir('/kaggle/input/dataset/idata/Image Dataset')}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:03.365819Z","iopub.execute_input":"2022-08-03T17:53:03.366581Z","iopub.status.idle":"2022-08-03T17:53:03.379410Z","shell.execute_reply.started":"2022-08-03T17:53:03.366535Z","shell.execute_reply":"2022-08-03T17:53:03.377140Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_dir = '/kaggle/input/dataset/idata/Image Dataset/test_data/'\n# print(f\"There are {len(os.listdir('/kaggle/input/newds/ImageDataset_new/ImageDataset_new/test_data'))} images for training\")\nos.listdir(test_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:03.669199Z","iopub.execute_input":"2022-08-03T17:53:03.669850Z","iopub.status.idle":"2022-08-03T17:53:03.682572Z","shell.execute_reply.started":"2022-08-03T17:53:03.669819Z","shell.execute_reply":"2022-08-03T17:53:03.680986Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for img in os.listdir(test_dir+'test'):\n        if not img.endswith('.JPG'):\n            print('Yes! I knew it!')","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:05.643885Z","iopub.execute_input":"2022-08-03T17:53:05.644452Z","iopub.status.idle":"2022-08-03T17:53:05.656387Z","shell.execute_reply.started":"2022-08-03T17:53:05.644407Z","shell.execute_reply":"2022-08-03T17:53:05.654681Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Data Preparation for training ","metadata":{}},{"cell_type":"markdown","source":"# datasets for validation and training\ntrain = ImageFolder(train_dir, \n                    transform = transforms.Compose([\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]))\n\nprint(train, '\\n')\nvalid = ImageFolder(valid_dir,\n                      transform = transforms.Compose([\n                                transforms.ToTensor(),\n                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]))\nprint(valid, '\\n')","metadata":{"execution":{"iopub.status.busy":"2022-07-10T11:26:20.076228Z","iopub.execute_input":"2022-07-10T11:26:20.076668Z","iopub.status.idle":"2022-07-10T11:26:22.591953Z","shell.execute_reply.started":"2022-07-10T11:26:20.076626Z","shell.execute_reply":"2022-07-10T11:26:22.591119Z"}}},{"cell_type":"markdown","source":"Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural networks works quite good with normalized data. The entire array of pixel values is converted to torch [tensor](https://pytorch.org/tutorials/beginner/examples_tensor/two_layer_net_tensor.html#:~:text=A%20PyTorch%20Tensor%20is%20basically,used%20for%20arbitrary%20numeric%20computation.) and then divided by 255.\nIf you are not familiar why normalizing inputs help neural network, read [this](https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d) post.","metadata":{}},{"cell_type":"code","source":"print(train_dir)\nprint(valid_dir)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:12.864948Z","iopub.execute_input":"2022-08-03T17:53:12.865457Z","iopub.status.idle":"2022-08-03T17:53:12.873934Z","shell.execute_reply.started":"2022-08-03T17:53:12.865424Z","shell.execute_reply":"2022-08-03T17:53:12.872263Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# datasets for validation and training\ntrain = ImageFolder(train_dir, transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))\n\nvalid = ImageFolder(valid_dir, transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:13.288261Z","iopub.execute_input":"2022-08-03T17:53:13.288716Z","iopub.status.idle":"2022-08-03T17:53:26.473127Z","shell.execute_reply.started":"2022-08-03T17:53:13.288681Z","shell.execute_reply":"2022-08-03T17:53:26.471685Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#Image shape\nimg, label = train[4590]\nprint(img.shape, label)\n\nimg, label = train[0]\nprint(img.shape, label)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:26.475990Z","iopub.execute_input":"2022-08-03T17:53:26.477011Z","iopub.status.idle":"2022-08-03T17:53:26.508447Z","shell.execute_reply.started":"2022-08-03T17:53:26.476933Z","shell.execute_reply":"2022-08-03T17:53:26.506902Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"We can see the shape (3, 256 256) of the image. 3 is the number of channels (RGB) and 256 x 256 is the width and height of the image","metadata":{}},{"cell_type":"code","source":"len(train.classes) #multiclass classification with 6 classes","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:27.981310Z","iopub.execute_input":"2022-08-03T17:53:27.981776Z","iopub.status.idle":"2022-08-03T17:53:27.991123Z","shell.execute_reply.started":"2022-08-03T17:53:27.981746Z","shell.execute_reply":"2022-08-03T17:53:27.989279Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# for checking some images from training dataset\ndef show_image(image, label):\n    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n    plt.imshow(image.permute(1, 2, 0))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:30.311990Z","iopub.execute_input":"2022-08-03T17:53:30.312905Z","iopub.status.idle":"2022-08-03T17:53:30.321101Z","shell.execute_reply.started":"2022-08-03T17:53:30.312861Z","shell.execute_reply":"2022-08-03T17:53:30.319067Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Setting the seed value\nrandom_seed = 7\ntorch.manual_seed(random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:30.707991Z","iopub.execute_input":"2022-08-03T17:53:30.708894Z","iopub.status.idle":"2022-08-03T17:53:30.723790Z","shell.execute_reply.started":"2022-08-03T17:53:30.708822Z","shell.execute_reply":"2022-08-03T17:53:30.722286Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"show_image(*train[10000])","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:31.173585Z","iopub.execute_input":"2022-08-03T17:53:31.174035Z","iopub.status.idle":"2022-08-03T17:53:31.433566Z","shell.execute_reply.started":"2022-08-03T17:53:31.174003Z","shell.execute_reply":"2022-08-03T17:53:31.432107Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"show_image(*train[6580])","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:31.642453Z","iopub.execute_input":"2022-08-03T17:53:31.643155Z","iopub.status.idle":"2022-08-03T17:53:31.910151Z","shell.execute_reply.started":"2022-08-03T17:53:31.643123Z","shell.execute_reply":"2022-08-03T17:53:31.908665Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"show_image(*train[1000])","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:33.112223Z","iopub.execute_input":"2022-08-03T17:53:33.112762Z","iopub.status.idle":"2022-08-03T17:53:33.393588Z","shell.execute_reply.started":"2022-08-03T17:53:33.112717Z","shell.execute_reply":"2022-08-03T17:53:33.391991Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"show_image(*train[5000])","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:33.396293Z","iopub.execute_input":"2022-08-03T17:53:33.396843Z","iopub.status.idle":"2022-08-03T17:53:33.648730Z","shell.execute_reply.started":"2022-08-03T17:53:33.396798Z","shell.execute_reply":"2022-08-03T17:53:33.647488Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(train, '\\n')\nprint(valid)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:33.749234Z","iopub.execute_input":"2022-08-03T17:53:33.750077Z","iopub.status.idle":"2022-08-03T17:53:33.758740Z","shell.execute_reply.started":"2022-08-03T17:53:33.750002Z","shell.execute_reply":"2022-08-03T17:53:33.757226Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# DataLoaders for training and validation\n# setting the batch size\nbatch_size = 32\ntrain_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\nvalid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:34.926569Z","iopub.execute_input":"2022-08-03T17:53:34.927621Z","iopub.status.idle":"2022-08-03T17:53:34.935964Z","shell.execute_reply.started":"2022-08-03T17:53:34.927562Z","shell.execute_reply":"2022-08-03T17:53:34.933793Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# helper function to show a batch of training instances\ndef show_batch(data):\n    for images, labels in data:\n        fig, ax = plt.subplots(figsize=(30, 30))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n        break\n        \n# Images for first batch of training\nshow_batch(train_dl) ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:36.873152Z","iopub.execute_input":"2022-08-03T17:53:36.874071Z","iopub.status.idle":"2022-08-03T17:53:43.732541Z","shell.execute_reply.started":"2022-08-03T17:53:36.874024Z","shell.execute_reply":"2022-08-03T17:53:43.727735Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# for moving data into GPU (if available)\ndef get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available:\n        return torch.device(\"cuda\")\n    else:\n        return torch.device(\"cpu\")\n\n# for moving data to device (CPU or GPU)\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# for loading in the device (GPU if available else CPU)\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl:\n            yield to_device(b, self.device)\n        \n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:48.293987Z","iopub.execute_input":"2022-08-03T17:53:48.295582Z","iopub.status.idle":"2022-08-03T17:53:48.308142Z","shell.execute_reply.started":"2022-08-03T17:53:48.295536Z","shell.execute_reply":"2022-08-03T17:53:48.306407Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:49.871567Z","iopub.execute_input":"2022-08-03T17:53:49.871982Z","iopub.status.idle":"2022-08-03T17:53:49.881434Z","shell.execute_reply.started":"2022-08-03T17:53:49.871950Z","shell.execute_reply":"2022-08-03T17:53:49.879844Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:50.941595Z","iopub.execute_input":"2022-08-03T17:53:50.942695Z","iopub.status.idle":"2022-08-03T17:53:50.950887Z","shell.execute_reply.started":"2022-08-03T17:53:50.942605Z","shell.execute_reply":"2022-08-03T17:53:50.948914Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class SimpleResidualBlock(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.relu1(out)\n        out = self.conv2(out)\n        return self.relu2(out) + x # ReLU can be applied before or after adding the input","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:52.848306Z","iopub.execute_input":"2022-08-03T17:53:52.848781Z","iopub.status.idle":"2022-08-03T17:53:52.860489Z","shell.execute_reply.started":"2022-08-03T17:53:52.848750Z","shell.execute_reply":"2022-08-03T17:53:52.858787Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# for calculating the accuracy\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\n\n# base class for the model\nclass ImageClassificationBase(nn.Module):\n    \n    def training_step(self, batch):\n        images, labels = batch\n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch\n        out = self(images)                   # Generate prediction\n        loss = F.cross_entropy(out, labels)  # Calculate loss\n        acc = accuracy(out, labels)          # Calculate accuracy\n        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n    \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x[\"val_loss\"] for x in outputs]\n        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n        epoch_accuracy = torch.stack(batch_accuracy).mean()\n        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:53.177409Z","iopub.execute_input":"2022-08-03T17:53:53.178747Z","iopub.status.idle":"2022-08-03T17:53:53.192459Z","shell.execute_reply.started":"2022-08-03T17:53:53.178687Z","shell.execute_reply":"2022-08-03T17:53:53.190619Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Architecture for training\n\n# convolution block with BatchNormalization\ndef ConvBlock(in_channels, out_channels, pool=False):\n    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n             nn.BatchNorm2d(out_channels),\n             nn.ReLU(inplace=True)]\n    if pool:\n        layers.append(nn.MaxPool2d(4))\n    return nn.Sequential(*layers)\n\n\n# resnet architecture \nclass ResNet9(ImageClassificationBase):\n    def __init__(self, in_channels, num_diseases):\n        super().__init__()\n        \n        self.conv1 = ConvBlock(in_channels, 64)\n        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n        \n        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n        \n        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n                                       nn.Flatten(),\n                                       nn.Linear(512, num_diseases), \n                                       nn.Softmax(dim=1))\n        \n    def forward(self, xb): # xb is the loaded batch\n        out = self.conv1(xb)\n        out = self.conv2(out)\n        out = self.res1(out) + out\n        out = self.conv3(out)\n        out = self.conv4(out)\n        out = self.res2(out) + out\n        out = self.classifier(out)\n        return out        ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:54.785594Z","iopub.execute_input":"2022-08-03T17:53:54.787971Z","iopub.status.idle":"2022-08-03T17:53:54.801416Z","shell.execute_reply.started":"2022-08-03T17:53:54.787924Z","shell.execute_reply":"2022-08-03T17:53:54.799875Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# defining the model and moving it to the GPU\nmodel = to_device(ResNet9(3, len(train.classes)), device) \nmodel","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:53:56.464008Z","iopub.execute_input":"2022-08-03T17:53:56.464417Z","iopub.status.idle":"2022-08-03T17:53:56.554347Z","shell.execute_reply.started":"2022-08-03T17:53:56.464387Z","shell.execute_reply":"2022-08-03T17:53:56.552851Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# defining the model and moving it to the GPU\nmodel_ri = to_device(ResNet9(3, len(train.classes)), device) \nmodel_ri","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:37:33.977621Z","iopub.execute_input":"2022-08-01T22:37:33.978640Z","iopub.status.idle":"2022-08-01T22:37:34.065202Z","shell.execute_reply.started":"2022-08-01T22:37:33.978597Z","shell.execute_reply":"2022-08-01T22:37:34.064226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting summary of the model\nINPUT_SHAPE = (3, 256, 256)\nprint(summary(model.cuda(), (INPUT_SHAPE)))","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:54:02.054202Z","iopub.execute_input":"2022-08-03T17:54:02.055218Z","iopub.status.idle":"2022-08-03T17:54:09.131357Z","shell.execute_reply.started":"2022-08-03T17:54:02.055149Z","shell.execute_reply":"2022-08-03T17:54:09.129931Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# getting summary of the model\nINPUT_SHAPE = (3, 256, 256)\nprint(summary(model_ri.cuda(), (INPUT_SHAPE)))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:37:39.713454Z","iopub.execute_input":"2022-08-01T22:37:39.714037Z","iopub.status.idle":"2022-08-01T22:37:39.733297Z","shell.execute_reply.started":"2022-08-01T22:37:39.713984Z","shell.execute_reply":"2022-08-01T22:37:39.732289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for training\n@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \n\ndef fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n                grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    \n    # scheduler for one cycle learniing rate\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n    \n    \n    for epoch in range(epochs):\n        # Training\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n    \n        # validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        \n    return history\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T17:54:13.912590Z","iopub.execute_input":"2022-08-03T17:54:13.913188Z","iopub.status.idle":"2022-08-03T17:54:13.937177Z","shell.execute_reply.started":"2022-08-03T17:54:13.913141Z","shell.execute_reply":"2022-08-03T17:54:13.935021Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = [evaluate(model, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-08-03T13:11:14.129953Z","iopub.execute_input":"2022-08-03T13:11:14.131135Z","iopub.status.idle":"2022-08-03T13:11:35.211424Z","shell.execute_reply.started":"2022-08-03T13:11:14.131082Z","shell.execute_reply":"2022-08-03T13:11:35.210139Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = [evaluate(model_ri, valid_dl)]\nhistory","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:37:47.732915Z","iopub.execute_input":"2022-08-01T22:37:47.733285Z","iopub.status.idle":"2022-08-01T22:38:00.324399Z","shell.execute_reply.started":"2022-08-01T22:37:47.733252Z","shell.execute_reply":"2022-08-01T22:38:00.323321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------","metadata":{}},{"cell_type":"markdown","source":"### Hyperparamter tuning with optuna","metadata":{}},{"cell_type":"markdown","source":"Code for hyperparameter tuning adapted from https://towardsdatascience.com/hyperparameter-tuning-of-neural-networks-with-optuna-and-pytorch-22e179efc837","metadata":{}},{"cell_type":"code","source":"len(valid_dl)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T21:34:54.694827Z","iopub.execute_input":"2022-08-01T21:34:54.695225Z","iopub.status.idle":"2022-08-01T21:34:54.703435Z","shell.execute_reply.started":"2022-08-01T21:34:54.695189Z","shell.execute_reply":"2022-08-01T21:34:54.702258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate(param, model, train_loader, val_loader, trial):\n    torch.cuda.empty_cache()\n    history = []\n    \n    #optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    optimizer = getattr(torch.optim, param['optimizer'])(model.parameters(), lr=param['max_lr'], weight_decay=param['weight_decay'])\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, param['max_lr'], epochs=param['epochs'], steps_per_epoch=len(train_loader))\n\n    for epoch in range(param['epochs']):\n        # Training\n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # gradient clipping\n            if param['grad_clip']: \n                nn.utils.clip_grad_value_(model.parameters(), param['grad_clip'])\n                \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # recording and updating learning rates\n            lrs.append(get_lr(optimizer))\n            sched.step()\n            \n        # validation\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        model.epoch_end(epoch, result)\n        history.append(result)\n        val_acc_last_epoch = history[-1]['val_accuracy'].item()   \n        \n        trial.report(val_acc_last_epoch, epoch)\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n        \n        return val_acc_last_epoch ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T20:06:37.150535Z","iopub.execute_input":"2022-08-03T20:06:37.150976Z","iopub.status.idle":"2022-08-03T20:06:37.164030Z","shell.execute_reply.started":"2022-08-03T20:06:37.150946Z","shell.execute_reply":"2022-08-03T20:06:37.162520Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params = {'max_lr': trial.suggest_loguniform('learning_rate', 0.01, 0.05),\n               'optimizer': trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"]),\n               'weight_decay': trial.suggest_loguniform('weight_decay', 1e-4, 1e-1),\n               'grad_clip': trial.suggest_float('grad_clip', 0.1, 0.4),\n               'epochs' : trial.suggest_int('epochs', 2, 10)\n              }\n    \n    val_accuracy = train_and_evaluate(params, model, train_dl, valid_dl, trial)\n#     trial.report(val_accuracy, epoch)\n#     if trial.should_prune():\n#         raise optuna.exceptions.TrialPruned()\n   \n    return val_accuracy #train_and_evaluate(params, model, train_dl, valid_dl)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T20:09:13.054309Z","iopub.execute_input":"2022-08-03T20:09:13.054742Z","iopub.status.idle":"2022-08-03T20:09:13.064427Z","shell.execute_reply.started":"2022-08-03T20:09:13.054710Z","shell.execute_reply":"2022-08-03T20:09:13.062469Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"%%time\nstudy = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(), pruner=optuna.pruners.MedianPruner())\nstudy.optimize(objective, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T20:09:14.104330Z","iopub.execute_input":"2022-08-03T20:09:14.105440Z","iopub.status.idle":"2022-08-03T20:59:29.422786Z","shell.execute_reply.started":"2022-08-03T20:09:14.105394Z","shell.execute_reply":"2022-08-03T20:59:29.421201Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"best_trial = study.best_trial\n\nfor key, value in best_trial.params.items():\n    print(\"{}: {}\".format(key, value))","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:01:05.382178Z","iopub.execute_input":"2022-08-03T21:01:05.382618Z","iopub.status.idle":"2022-08-03T21:01:05.393467Z","shell.execute_reply.started":"2022-08-03T21:01:05.382583Z","shell.execute_reply":"2022-08-03T21:01:05.391731Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing the hyperparameter tuning process","metadata":{}},{"cell_type":"code","source":"plt.rcParams.update({\n    \"figure.facecolor\":  (1.0, 0.0, 0.0, 0.3),  # red   with alpha = 30%\n    \"axes.facecolor\":    (0.0, 1.0, 0.0, 0.5),  # green with alpha = 50%\n    \"savefig.facecolor\": (0.0, 0.0, 1.0, 0.2),  # blue  with alpha = 20%\n})","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:45:15.692113Z","iopub.execute_input":"2022-08-03T21:45:15.692579Z","iopub.status.idle":"2022-08-03T21:45:15.700386Z","shell.execute_reply.started":"2022-08-03T21:45:15.692549Z","shell.execute_reply":"2022-08-03T21:45:15.698433Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.plot_intermediate_values(study)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:45:19.710150Z","iopub.execute_input":"2022-08-03T21:45:19.710544Z","iopub.status.idle":"2022-08-03T21:45:19.748609Z","shell.execute_reply.started":"2022-08-03T21:45:19.710512Z","shell.execute_reply":"2022-08-03T21:45:19.746534Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"# optuna.visualization.plot_optimization_history(study)  #visualizing the tuning \noptuna.visualization.matplotlib.plot_optimization_history(study)\nplt.rcParams['figure.figsize']=[8,8]\nplt.rcParams['figure.facecolor'] = 'white'\n#plt.grid(color='#EAE4E3')\nplt.tight_layout()\nplt.savefig('/kaggle/working/temp.png', dpi=600, bbox_inches=\"tight\")\n# plt.savefig('/kaggle/working/gblurred_sample_imgs.png', dpi=600, bbox_inches=\"tight\")  #sample images and their corresponding andom rotations","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:45:29.502219Z","iopub.execute_input":"2022-08-03T21:45:29.502818Z","iopub.status.idle":"2022-08-03T21:45:33.066649Z","shell.execute_reply.started":"2022-08-03T21:45:29.502783Z","shell.execute_reply":"2022-08-03T21:45:33.065207Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"# optuna.visualization.plot_param_importances(study) #visualizing the parameter importances\noptuna.visualization.matplotlib.plot_param_importances(study) #i can modify the plot\nplt.tight_layout()\nplt.savefig('/kaggle/working/hyparam_importances_plot.png', dpi=600, bbox_inches=\"tight\")\n#plt.grid(color='#EAE4E3')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:40:53.880010Z","iopub.execute_input":"2022-08-03T21:40:53.880432Z","iopub.status.idle":"2022-08-03T21:40:56.570229Z","shell.execute_reply.started":"2022-08-03T21:40:53.880400Z","shell.execute_reply":"2022-08-03T21:40:56.568686Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.matplotlib.plot_contour","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:24:53.078299Z","iopub.execute_input":"2022-08-03T21:24:53.078733Z","iopub.status.idle":"2022-08-03T21:26:22.172201Z","shell.execute_reply.started":"2022-08-03T21:24:53.078701Z","shell.execute_reply":"2022-08-03T21:26:22.170668Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"optuna.visualization.matplotlib.plot_edf(study)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:27:48.725619Z","iopub.execute_input":"2022-08-03T21:27:48.726127Z","iopub.status.idle":"2022-08-03T21:27:48.981334Z","shell.execute_reply.started":"2022-08-03T21:27:48.726095Z","shell.execute_reply":"2022-08-03T21:27:48.979951Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"learning_rate: 0.010135175967178889\noptimizer: SGD\nweight_decay: 0.00014449224704403982\ngrad_clip: 0.22419147066847245\nepochs: 5\n    \n    \n    \nlearning_rate: 0.015314890666634384\noptimizer: SGD\nweight_decay: 0.0014905326547439307\ngrad_clip: 0.34833237106578674\nepochs: 3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To-Do!","metadata":{"execution":{"iopub.status.busy":"2022-07-27T14:38:33.714931Z","iopub.execute_input":"2022-07-27T14:38:33.715345Z","iopub.status.idle":"2022-07-27T14:38:33.722916Z","shell.execute_reply.started":"2022-07-27T14:38:33.715309Z","shell.execute_reply":"2022-07-27T14:38:33.721072Z"}}},{"cell_type":"markdown","source":"1. change hyper params and see how accuracy changes\n3. You have too many bullet points in overleaf, make them paragraph-y","metadata":{}},{"cell_type":"markdown","source":"---------------------","metadata":{"execution":{"iopub.status.busy":"2022-07-26T05:03:50.519722Z","iopub.execute_input":"2022-07-26T05:03:50.520435Z","iopub.status.idle":"2022-07-26T05:03:50.555171Z","shell.execute_reply.started":"2022-07-26T05:03:50.520370Z","shell.execute_reply":"2022-07-26T05:03:50.551821Z"}}},{"cell_type":"code","source":"epochs = 5\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.SGD\n#opt_func = torch.optim.Adam","metadata":{"execution":{"iopub.status.busy":"2022-08-03T19:27:25.941400Z","iopub.execute_input":"2022-08-03T19:27:25.941843Z","iopub.status.idle":"2022-08-03T19:27:25.949136Z","shell.execute_reply.started":"2022-08-03T19:27:25.941810Z","shell.execute_reply":"2022-08-03T19:27:25.947680Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"epochs = 3\nmax_lr = 0.015314890666634384\ngrad_clip = 0.34833237106578674\nweight_decay = 0.0014905326547439307\nopt_func = torch.optim.SGD\n# learning_rate:\n# optimizer: SGD\n# weight_decay: \n# grad_clip: \n# epochs: 3","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:03:30.178097Z","iopub.execute_input":"2022-08-03T21:03:30.178518Z","iopub.status.idle":"2022-08-03T21:03:30.186455Z","shell.execute_reply.started":"2022-08-03T21:03:30.178486Z","shell.execute_reply":"2022-08-03T21:03:30.184560Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"%%time\n#model 1 -> good model\nhistory += fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=1e-4, \n                             opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T13:12:35.477647Z","iopub.execute_input":"2022-08-03T13:12:35.478724Z","iopub.status.idle":"2022-08-03T13:20:40.910667Z","shell.execute_reply.started":"2022-08-03T13:12:35.478684Z","shell.execute_reply":"2022-08-03T13:20:40.909451Z"}}},{"cell_type":"code","source":"%%time\n# #model 1 -> good model\n# epochs=5\n# max_lr = 0.01\n# opt_func = torch.optim.SGD\nhistory = fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T21:04:01.701543Z","iopub.execute_input":"2022-08-03T21:04:01.701926Z","iopub.status.idle":"2022-08-03T21:09:01.242566Z","shell.execute_reply.started":"2022-08-03T21:04:01.701897Z","shell.execute_reply":"2022-08-03T21:09:01.240878Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"%%time\n#model 2 -> not very good model\nepochs=2\nmax_lr = 0.05\nopt_func = torch.optim.SGD\nhistory += fit_OneCycle(epochs, max_lr, model_ri, train_dl, valid_dl, \n                             grad_clip=0.4, \n                             weight_decay=1e-1, \n                             opt_func=opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:44:24.754349Z","iopub.execute_input":"2022-08-01T22:44:24.755443Z","iopub.status.idle":"2022-08-01T22:47:36.718734Z","shell.execute_reply.started":"2022-08-01T22:44:24.755390Z","shell.execute_reply":"2022-08-01T22:47:36.716549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history[-1]['val_loss'].item() #we ","metadata":{"execution":{"iopub.status.busy":"2022-08-03T14:01:08.156814Z","iopub.execute_input":"2022-08-03T14:01:08.157198Z","iopub.status.idle":"2022-08-03T14:01:08.165125Z","shell.execute_reply.started":"2022-08-03T14:01:08.157165Z","shell.execute_reply":"2022-08-03T14:01:08.163932Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"accs = []\n# [accs.append(history[i]['val_accuracy'].item()) for i in history]\nfor i in history:\n    #print(i['val_accuracy'], '\\n')\n    accs.append((i['val_accuracy'].item()))\nsum(accs)/len(accs)","metadata":{"execution":{"iopub.status.busy":"2022-08-03T19:12:18.073816Z","iopub.execute_input":"2022-08-03T19:12:18.074304Z","iopub.status.idle":"2022-08-03T19:12:18.388953Z","shell.execute_reply.started":"2022-08-03T19:12:18.074271Z","shell.execute_reply":"2022-08-03T19:12:18.386679Z"}}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_accuracy'] for x in history]\n    plt.grid(color='#EAE4E3')\n    plt.plot(accuracies, '-x', color='black')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');\n\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x.get('val_loss').cpu().numpy() for x in history] #[x['val_loss'] for x in history]\n    plt.grid(color='#EAE4E3')\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \ndef plot_lrs(history):\n    lrs = np.concatenate([x.get('lrs', []) for x in history])\n    plt.grid(color='#EAE4E3')\n    plt.plot(lrs)\n    plt.xlabel('Batch no.')\n    plt.ylabel('Learning rate')\n    plt.title('Learning Rate vs. Batch no.');","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:03.454904Z","iopub.execute_input":"2022-08-01T22:48:03.455925Z","iopub.status.idle":"2022-08-01T22:48:03.468656Z","shell.execute_reply.started":"2022-08-01T22:48:03.455885Z","shell.execute_reply":"2022-08-01T22:48:03.467688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation accuracy\nplot_accuracies(history)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:04.322451Z","iopub.execute_input":"2022-08-01T22:48:04.323403Z","iopub.status.idle":"2022-08-01T22:48:04.515205Z","shell.execute_reply.started":"2022-08-01T22:48:04.323339Z","shell.execute_reply":"2022-08-01T22:48:04.514283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validation loss\nplot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:39.761410Z","iopub.execute_input":"2022-08-01T22:48:39.761795Z","iopub.status.idle":"2022-08-01T22:48:39.963342Z","shell.execute_reply.started":"2022-08-01T22:48:39.761761Z","shell.execute_reply":"2022-08-01T22:48:39.962378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Learning Rate overtime\nplot_lrs(history)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:46.973219Z","iopub.execute_input":"2022-08-01T22:48:46.973925Z","iopub.status.idle":"2022-08-01T22:48:47.229731Z","shell.execute_reply.started":"2022-08-01T22:48:46.973876Z","shell.execute_reply":"2022-08-01T22:48:47.228788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.listdir('../input/imagedataset/ImageDataset/test_data')\n# os.listdir('../test')","metadata":{"execution":{"iopub.status.busy":"2022-07-31T16:20:23.208168Z","iopub.execute_input":"2022-07-31T16:20:23.208906Z","iopub.status.idle":"2022-07-31T16:20:23.213169Z","shell.execute_reply.started":"2022-07-31T16:20:23.208866Z","shell.execute_reply":"2022-07-31T16:20:23.212078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Creating a new test dir bcause there was an svn file or folder found in the test dir\nos.mkdir('../test_data')\nos.mkdir('../test_data/test')","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:55.521687Z","iopub.execute_input":"2022-08-01T22:48:55.522283Z","iopub.status.idle":"2022-08-01T22:48:55.529447Z","shell.execute_reply.started":"2022-08-01T22:48:55.522244Z","shell.execute_reply":"2022-08-01T22:48:55.528469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir_old = test_dir\ntest_dir_new = '../test_data'\nprint(test_dir_old)\nprint(test_dir_new)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:56.272331Z","iopub.execute_input":"2022-08-01T22:48:56.272725Z","iopub.status.idle":"2022-08-01T22:48:56.278691Z","shell.execute_reply.started":"2022-08-01T22:48:56.272693Z","shell.execute_reply":"2022-08-01T22:48:56.277703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir_old","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:57.147680Z","iopub.execute_input":"2022-08-01T22:48:57.148349Z","iopub.status.idle":"2022-08-01T22:48:57.154692Z","shell.execute_reply.started":"2022-08-01T22:48:57.148310Z","shell.execute_reply":"2022-08-01T22:48:57.153428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###Moving file from old test dir to new test dir\nnum_moved = 0\nfor img in os.listdir(test_dir_old+'test'):\n    if img.endswith('.JPG'):\n        shutil.copy(f\"{test_dir_old+'test/'}{img}\", f\"{test_dir_new+'/test/'}{img}\")\n        num_moved += 1\n    else:\n        print('not going to move you!')\nprint(f\"Number of files moved: {num_moved}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:48:59.397933Z","iopub.execute_input":"2022-08-01T22:48:59.398828Z","iopub.status.idle":"2022-08-01T22:49:10.822991Z","shell.execute_reply.started":"2022-08-01T22:48:59.398777Z","shell.execute_reply":"2022-08-01T22:49:10.821996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(os.listdir('../test_data/test')) #files have been moved","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:10.825152Z","iopub.execute_input":"2022-08-01T22:49:10.825567Z","iopub.status.idle":"2022-08-01T22:49:10.836316Z","shell.execute_reply.started":"2022-08-01T22:49:10.825526Z","shell.execute_reply":"2022-08-01T22:49:10.835407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing model on test data\ntest = ImageFolder(test_dir_new, transform=transforms.Compose(\n                                        [transforms.Resize([256, 256]),\n                                         transforms.ToTensor()]))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:10.837706Z","iopub.execute_input":"2022-08-01T22:49:10.838842Z","iopub.status.idle":"2022-08-01T22:49:10.852888Z","shell.execute_reply.started":"2022-08-01T22:49:10.838804Z","shell.execute_reply":"2022-08-01T22:49:10.851847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:13.981356Z","iopub.execute_input":"2022-08-01T22:49:13.981997Z","iopub.status.idle":"2022-08-01T22:49:13.989269Z","shell.execute_reply.started":"2022-08-01T22:49:13.981956Z","shell.execute_reply":"2022-08-01T22:49:13.988287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = sorted(os.listdir(test_dir_new + '/test')) # since images in test folder are not in alphabetical order\n#test_images","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:17.199924Z","iopub.execute_input":"2022-08-01T22:49:17.200617Z","iopub.status.idle":"2022-08-01T22:49:17.208125Z","shell.execute_reply.started":"2022-08-01T22:49:17.200576Z","shell.execute_reply":"2022-08-01T22:49:17.207058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_image(img, model):\n    \"\"\"Converts image to array and return the predicted class\n        with highest probability\"\"\"\n    # Convert to a batch of 1\n    xb = to_device(img.unsqueeze(0), device)\n    # Get predictions from model\n    yb = model(xb)\n    # Pick index with highest probability\n    _, preds  = torch.max(yb, dim=1)\n    # Retrieve the class label\n\n    return train.classes[preds[0].item()]","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:17.844491Z","iopub.execute_input":"2022-08-01T22:49:17.844868Z","iopub.status.idle":"2022-08-01T22:49:17.854056Z","shell.execute_reply.started":"2022-08-01T22:49:17.844834Z","shell.execute_reply":"2022-08-01T22:49:17.853081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:19.916184Z","iopub.execute_input":"2022-08-01T22:49:19.916928Z","iopub.status.idle":"2022-08-01T22:49:19.926754Z","shell.execute_reply.started":"2022-08-01T22:49:19.916886Z","shell.execute_reply":"2022-08-01T22:49:19.924117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = test[0]\nlabel","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:20.843505Z","iopub.execute_input":"2022-08-01T22:49:20.844602Z","iopub.status.idle":"2022-08-01T22:49:20.856165Z","shell.execute_reply.started":"2022-08-01T22:49:20.844548Z","shell.execute_reply":"2022-08-01T22:49:20.854981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_images))\nprint(len(test))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:21.255543Z","iopub.execute_input":"2022-08-01T22:49:21.256121Z","iopub.status.idle":"2022-08-01T22:49:21.261201Z","shell.execute_reply.started":"2022-08-01T22:49:21.256086Z","shell.execute_reply":"2022-08-01T22:49:21.260175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting first image\nimg, label = test[-100]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_images[-100], ', Predicted:', predict_image(img, model))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:23.445688Z","iopub.execute_input":"2022-08-01T22:49:23.446062Z","iopub.status.idle":"2022-08-01T22:49:23.681509Z","shell.execute_reply.started":"2022-08-01T22:49:23.446031Z","shell.execute_reply":"2022-08-01T22:49:23.680308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predicting first image\nimg, label = test[-100]\nplt.imshow(img.permute(1, 2, 0))\nprint('Label:', test_images[-100], ', Predicted:', predict_image(img, model_ri))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:40.688226Z","iopub.execute_input":"2022-08-01T22:49:40.688923Z","iopub.status.idle":"2022-08-01T22:49:40.901422Z","shell.execute_reply.started":"2022-08-01T22:49:40.688881Z","shell.execute_reply":"2022-08-01T22:49:40.900371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f\"{test_images[0].split('_')[0] + '_'  + test_images[0].split('_')[1]}\"","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:48.026202Z","iopub.execute_input":"2022-08-01T22:49:48.026789Z","iopub.status.idle":"2022-08-01T22:49:48.034201Z","shell.execute_reply.started":"2022-08-01T22:49:48.026749Z","shell.execute_reply":"2022-08-01T22:49:48.033198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting all predictions (actual label vs predicted)\nlistt = []\nfor i, (img, label) in enumerate(test):\n    #print('Label:', test_images[i], ', Predicted:', predict_image(img, model))\n    listt.append((f\"{test_images[i].split('_')[0] + '_'+ test_images[i].split('_')[1]}\", predict_image(img, model)))\n    \n#listt","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:49:48.857403Z","iopub.execute_input":"2022-08-01T22:49:48.858084Z","iopub.status.idle":"2022-08-01T22:49:48.885176Z","shell.execute_reply.started":"2022-08-01T22:49:48.858046Z","shell.execute_reply":"2022-08-01T22:49:48.883775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting all predictions (actual label vs predicted)\nlistt = []\nfor i, (img, label) in enumerate(test):\n    #print('Label:', test_images[i], ', Predicted:', predict_image(img, model))\n    listt.append((f\"{test_images[i].split('_')[0] + '_'+ test_images[i].split('_')[1]}\", predict_image(img, model_ri)))\n    \n#listt","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:50:02.773394Z","iopub.execute_input":"2022-08-01T22:50:02.773768Z","iopub.status.idle":"2022-08-01T22:50:09.535072Z","shell.execute_reply.started":"2022-08-01T22:50:02.773735Z","shell.execute_reply":"2022-08-01T22:50:09.534078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nfor tup in listt:\n    if tup[0]==tup[1]:\n        count+=1\ntest_accuracy = count/len(listt)*100\nprint(round(test_accuracy, 2))","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:50:10.993537Z","iopub.execute_input":"2022-08-01T22:50:10.993910Z","iopub.status.idle":"2022-08-01T22:50:11.001486Z","shell.execute_reply.started":"2022-08-01T22:50:10.993879Z","shell.execute_reply":"2022-08-01T22:50:11.000523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model #check if the softmax layer is present before you save the model","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:54:12.884357Z","iopub.execute_input":"2022-08-01T22:54:12.884980Z","iopub.status.idle":"2022-08-01T22:54:12.907773Z","shell.execute_reply.started":"2022-08-01T22:54:12.884942Z","shell.execute_reply":"2022-08-01T22:54:12.906390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ri","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:54:19.756675Z","iopub.execute_input":"2022-08-01T22:54:19.757251Z","iopub.status.idle":"2022-08-01T22:54:19.764676Z","shell.execute_reply.started":"2022-08-01T22:54:19.757213Z","shell.execute_reply":"2022-08-01T22:54:19.763615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving to the kaggle working directory ###check this again\nPATH1 = './pt-mdlsd.pth'  \ntorch.save(model.state_dict(), PATH1)\n\nPATH2 = './pt-mdl.pth' \ntorch.save(model, PATH2)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:54:35.513325Z","iopub.execute_input":"2022-08-01T22:54:35.513738Z","iopub.status.idle":"2022-08-01T22:54:35.536643Z","shell.execute_reply.started":"2022-08-01T22:54:35.513705Z","shell.execute_reply":"2022-08-01T22:54:35.535339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving to the kaggle working directory ###check this again\nPATH1 = './ptri-mdlsd.pth'  \ntorch.save(model_ri.state_dict(), PATH1)\n\nPATH2 = './ptri-mdl.pth' \ntorch.save(model_ri, PATH2)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:55:17.607173Z","iopub.execute_input":"2022-08-01T22:55:17.607557Z","iopub.status.idle":"2022-08-01T22:55:17.716174Z","shell.execute_reply.started":"2022-08-01T22:55:17.607524Z","shell.execute_reply":"2022-08-01T22:55:17.715185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking feature importances","metadata":{"execution":{"iopub.status.busy":"2022-07-12T19:16:11.586831Z","iopub.execute_input":"2022-07-12T19:16:11.587587Z","iopub.status.idle":"2022-07-12T19:16:11.605472Z","shell.execute_reply.started":"2022-07-12T19:16:11.587481Z","shell.execute_reply":"2022-07-12T19:16:11.604600Z"}}},{"cell_type":"code","source":"type(train_dl)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:56:28.678941Z","iopub.execute_input":"2022-08-01T22:56:28.679431Z","iopub.status.idle":"2022-08-01T22:56:28.687460Z","shell.execute_reply.started":"2022-08-01T22:56:28.679352Z","shell.execute_reply":"2022-08-01T22:56:28.686325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Moving data into GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:56:29.537092Z","iopub.execute_input":"2022-08-01T22:56:29.537500Z","iopub.status.idle":"2022-08-01T22:56:29.542708Z","shell.execute_reply.started":"2022-08-01T22:56:29.537465Z","shell.execute_reply":"2022-08-01T22:56:29.541379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader_r = torch.utils.data.DataLoader(test, \n                                            batch_size=batch_size,\n                                            shuffle=True)\n\ntest_loader_r = DeviceDataLoader(test_loader_r, device)\ntest_loader_r","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:56:30.599775Z","iopub.execute_input":"2022-08-01T22:56:30.600768Z","iopub.status.idle":"2022-08-01T22:56:30.609439Z","shell.execute_reply.started":"2022-08-01T22:56:30.600720Z","shell.execute_reply":"2022-08-01T22:56:30.607984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"batch = next(iter(test_loader_r))\nimages, _ = batch\n\nbackground = images[:20]\ntest_images = images[20:24]\n\ne = shap.DeepExplainer(model, background)\nshap_values = e.shap_values(test_images)","metadata":{"execution":{"iopub.status.busy":"2022-07-19T12:31:43.901518Z","iopub.execute_input":"2022-07-19T12:31:43.902242Z","iopub.status.idle":"2022-07-19T12:31:54.221321Z","shell.execute_reply.started":"2022-07-19T12:31:43.902201Z","shell.execute_reply":"2022-07-19T12:31:54.220305Z"}}},{"cell_type":"markdown","source":"shap_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values] #how can you add the predicted label vs true label to plot\ntest_numpy = np.swapaxes(np.swapaxes(test_images.cpu().numpy(), 1, -1), 1, 2)\n# plot the feature attributions\nshap.image_plot(shap_numpy, -test_numpy)\n#plt.rcParams['figure.figsize'] = [10, 10]","metadata":{"execution":{"iopub.status.busy":"2022-07-19T12:32:02.524092Z","iopub.execute_input":"2022-07-19T12:32:02.524759Z","iopub.status.idle":"2022-07-19T12:32:04.671878Z","shell.execute_reply.started":"2022-07-19T12:32:02.524722Z","shell.execute_reply":"2022-07-19T12:32:04.670944Z"}}},{"cell_type":"code","source":"# since shuffle=True, this is a random sample of test data\nimages, targets =  next(iter(test_loader_r))\nBACKGROUND_SIZE = 20\nbackground_images = images[:BACKGROUND_SIZE]\nbackground_targets = targets[:BACKGROUND_SIZE].cpu().numpy()\n#increase the size after you've fixed everything \n\ntest_images = images[BACKGROUND_SIZE:BACKGROUND_SIZE+9]\ntest_targets = targets[BACKGROUND_SIZE:BACKGROUND_SIZE+9].cpu().numpy()\ndef show_attributions(model):\n    # predict the probabilities of the digits using the test images\n    output = model(test_images.to(device))\n    # get the index of the max log-probability\n    pred = output.max(1, keepdim=True)[1] \n    # convert to numpy only once to save time\n    pred_np = pred.cpu().numpy() \n\n    expl = shap.DeepExplainer(model, background_images)\n    train_classes = ['potato_early', 'potato_healthy', 'potato_late', 'tomato_early', 'tomato_healthy', 'tomato_late'] \n    for i in range(0, len(test_images)):\n        warnings.filterwarnings('ignore')\n        \n        torch.cuda.empty_cache()\n        ti = test_images[[i]]\n        sv = expl.shap_values(ti)\n        sn = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in sv]\n        tn = np.swapaxes(np.swapaxes(ti.cpu().numpy(), 1, -1), 1, 2) #.cpu().numpy()?\n\n        # Prepare the attribution plot, but do not draw it yet\n        # We will add more info to the plots later in the code\n        shap.image_plot(sn, -tn, show=False)\n\n        # Prepare to augment the plot\n        fig = plt.gcf()\n        allaxes = fig.get_axes()\n\n        # Show the actual/predicted class\n        #plot the original image here as well\n        allaxes[0].set_title('Actual: {}, Pred: {}'.format(train_classes[test_targets[i]], train_classes[pred_np[i][0]]), fontsize=10)\n        \n        \n        # Show the probability of each class\n        # There are 11 axes for each picture: 1 for the digit + 10 for each SHAP\n        # There is a last axis for the scale - we don't want to apply a label for that one\n        prob = output[i].detach().cpu().numpy()\n        for x in range(1, len(allaxes)-1):\n            #allaxes[x].set_title('{}'.format(train_classes[x-1]), fontsize=10)\n            allaxes[x].set_title('{}({:.2%})'.format(train_classes[x-1], prob[x-1]), fontsize=10)\n            allaxes[0].imshow(test_images[i].cpu().permute(1, 2, 0))\n#            \n#             allaxes[x].set_title('{}({:.2%})'.format(train_classes[x-1], prob[x-1]), fontsize=9)            \n\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:56:37.507416Z","iopub.execute_input":"2022-08-01T22:56:37.508018Z","iopub.status.idle":"2022-08-01T22:56:37.614356Z","shell.execute_reply.started":"2022-08-01T22:56:37.507979Z","shell.execute_reply":"2022-08-01T22:56:37.613412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_attributions = show_attributions(model)\nfeature_attributions","metadata":{"execution":{"iopub.status.busy":"2022-07-30T12:52:19.658037Z","iopub.execute_input":"2022-07-30T12:52:19.658394Z","iopub.status.idle":"2022-07-30T12:52:54.273758Z","shell.execute_reply.started":"2022-07-30T12:52:19.658363Z","shell.execute_reply":"2022-07-30T12:52:54.272338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_attributions = show_attributions(model_ri)","metadata":{"execution":{"iopub.status.busy":"2022-08-01T22:56:50.783700Z","iopub.execute_input":"2022-08-01T22:56:50.784073Z","iopub.status.idle":"2022-08-01T22:57:26.393185Z","shell.execute_reply.started":"2022-08-01T22:56:50.784041Z","shell.execute_reply":"2022-08-01T22:57:26.392013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(feature_attributions)","metadata":{"execution":{"iopub.status.busy":"2022-07-30T12:53:35.342706Z","iopub.execute_input":"2022-07-30T12:53:35.343075Z","iopub.status.idle":"2022-07-30T12:53:35.350947Z","shell.execute_reply.started":"2022-07-30T12:53:35.343043Z","shell.execute_reply":"2022-07-30T12:53:35.349926Z"},"trusted":true},"execution_count":null,"outputs":[]}]}